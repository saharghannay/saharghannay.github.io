<!DOCTYPE html>
<html lang="en-us">

<head>

  <meta charset="utf-8">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <meta http-equiv="X-UA-Compatible" content="IE=edge">
  <meta name="generator" content="Source Themes Academic 4.6.3">

  

  
  
  
  
  
    
    
    
  
  

  <meta name="author" content="Sahar Ghannay">

  
  
  
    
  
  <meta name="description" content="[English version below]
Objectif L&#39;objectif du TP est de construire et de comparer différents type de plongements lexicaux (embeddings de mots) en utilisant les bibliothèques gensim et fasttext.
Ces embeddings seront entrainés sur deux corpus différents : corpus en domaine médical (QUAERO_FrenchMed) de petit taille et un corpus non médical (QUAERO_FrenchPress) de grand taille. Ils seront évaluer sur la tâche de détection d’entités nommées (NER : Named Entity recognition) pendant le TP2 (l’après midi).">

  
  <link rel="alternate" hreflang="en-us" href="https://saharghannay.github.io/courses/cours1/example1/">

  


  
  
  
  <meta name="theme-color" content="#3f51b5">
  

  
  
  
  
    
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/academicons/1.8.6/css/academicons.min.css" integrity="sha256-uFVgMKfistnJAfoCUQigIl+JfUaP47GrRKjf6CTPVmw=" crossorigin="anonymous">
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.11.2/css/all.min.css" integrity="sha256-+N4/V/SbAFiW1MPBCXnfnP9QSN3+Keu+NlB+0ev/YKQ=" crossorigin="anonymous">
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/fancybox/3.5.7/jquery.fancybox.min.css" integrity="sha256-Vzbj7sDDS/woiFS3uNKo8eIuni59rjyNGtXfstRzStA=" crossorigin="anonymous">

    
    
    
      
    
    
      
      
        
          <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/9.15.10/styles/github.min.css" crossorigin="anonymous" title="hl-light">
          <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/9.15.10/styles/dracula.min.css" crossorigin="anonymous" title="hl-dark" disabled>
        
      
    

    
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/leaflet/1.5.1/leaflet.css" integrity="sha256-SHMGCYmST46SoyGgo4YR/9AlK1vf3ff84Aq9yK4hdqM=" crossorigin="anonymous">
    

    

  

  
  
  
  <link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Cutive+Mono%7CLora:400,700%7CRoboto:400,700&display=swap">
  

  
  
  
  
  <link rel="stylesheet" href="/css/academic.css">

  





<script async src="https://www.googletagmanager.com/gtag/js?id=UA-168612420-1"></script>
<script>
  window.dataLayer = window.dataLayer || [];

  function gtag() {
      dataLayer.push(arguments);
  }

  function trackOutboundLink(url) {
    gtag('event', 'click', {
         'event_category': 'outbound',
         'event_label': url,
         'transport_type': 'beacon',
         'event_callback': function () {
           document.location = url;
         }
    });
    console.debug("Outbound link clicked: " + url);
  }

  function onClickCallback(event) {
    if ((event.target.tagName !== 'A') || (event.target.host === window.location.host)) {
      return;
    }
    trackOutboundLink(event.target);  
  }

  gtag('js', new Date());
  gtag('config', 'UA-168612420-1', {});

  
  document.addEventListener('click', onClickCallback, false);
</script>


  


  

  <link rel="manifest" href="/index.webmanifest">
  <link rel="icon" type="image/png" href="/img/icon-32.png">
  <link rel="apple-touch-icon" type="image/png" href="/img/icon-192.png">

  <link rel="canonical" href="https://saharghannay.github.io/courses/cours1/example1/">

  
  
  
  
    
    
  
  
  <meta property="twitter:card" content="summary">
  
  <meta property="og:site_name" content="Sahar Ghannay">
  <meta property="og:url" content="https://saharghannay.github.io/courses/cours1/example1/">
  <meta property="og:title" content="Word embeddings training | Sahar Ghannay">
  <meta property="og:description" content="[English version below]
Objectif L&#39;objectif du TP est de construire et de comparer différents type de plongements lexicaux (embeddings de mots) en utilisant les bibliothèques gensim et fasttext.
Ces embeddings seront entrainés sur deux corpus différents : corpus en domaine médical (QUAERO_FrenchMed) de petit taille et un corpus non médical (QUAERO_FrenchPress) de grand taille. Ils seront évaluer sur la tâche de détection d’entités nommées (NER : Named Entity recognition) pendant le TP2 (l’après midi)."><meta property="og:image" content="https://saharghannay.github.io/img/icon-192.png">
  <meta property="twitter:image" content="https://saharghannay.github.io/img/icon-192.png"><meta property="og:locale" content="en-us">
  
    
      <meta property="article:published_time" content="2018-05-05T00:00:00&#43;01:00">
    
    <meta property="article:modified_time" content="2020-09-09T00:00:00&#43;00:00">
  

  



  


  


  





  <title>Word embeddings training | Sahar Ghannay</title>

</head>

<body id="top" data-spy="scroll" data-offset="70" data-target="#TableOfContents" >

  <aside class="search-results" id="search">
  <div class="container">
    <section class="search-header">

      <div class="row no-gutters justify-content-between mb-3">
        <div class="col-6">
          <h1>Search</h1>
        </div>
        <div class="col-6 col-search-close">
          <a class="js-search" href="#"><i class="fas fa-times-circle text-muted" aria-hidden="true"></i></a>
        </div>
      </div>

      <div id="search-box">
        
        <input name="q" id="search-query" placeholder="Search..." autocapitalize="off"
        autocomplete="off" autocorrect="off" spellcheck="false" type="search">
        
      </div>

    </section>
    <section class="section-search-results">

      <div id="search-hits">
        
      </div>

    </section>
  </div>
</aside>


  

<nav class="navbar navbar-expand-lg navbar-light compensate-for-scrollbar" id="navbar-main">
  <div class="container">

    
    <div class="d-none d-lg-inline-flex">
      <a class="navbar-brand" href="/">Sahar Ghannay</a>
    </div>
    

    
    <button type="button" class="navbar-toggler" data-toggle="collapse"
            data-target="#navbar-content" aria-controls="navbar" aria-expanded="false" aria-label="Toggle navigation">
    <span><i class="fas fa-bars"></i></span>
    </button>
    

    
    <div class="navbar-brand-mobile-wrapper d-inline-flex d-lg-none">
      <a class="navbar-brand" href="/">Sahar Ghannay</a>
    </div>
    

    
    
    <div class="navbar-collapse main-menu-item collapse justify-content-end" id="navbar-content">

      
      <ul class="navbar-nav d-md-inline-flex">
        

        

        
        
        
          
        

        
        
        
        
        
        
          
          
          
            
          
          
        

        <li class="nav-item">
          <a class="nav-link " href="/#about"><span>Home</span></a>
        </li>

        
        

        

        
        
        
          
        

        
        
        
        
        
        
          
          
          
            
          
          
        

        <li class="nav-item">
          <a class="nav-link " href="/#research"><span>Research</span></a>
        </li>

        
        

        

        
        
        
          
        

        
        
        
        
        
        
          
          
          
            
          
          
        

        <li class="nav-item">
          <a class="nav-link " href="/#publications"><span>Publications</span></a>
        </li>

        
        

        

        
        
        
          
        

        
        
        
        
        
        

        <li class="nav-item">
          <a class="nav-link  active" href="/courses/"><span>Teaching</span></a>
        </li>

        
        

        

        
        
        
          
        

        
        
        
        
        
        
          
          
          
            
          
          
        

        <li class="nav-item">
          <a class="nav-link " href="/#contact"><span>Contact</span></a>
        </li>

        
        

      

        
      </ul>
    </div>

    <ul class="nav-icons navbar-nav flex-row ml-auto d-flex pl-md-2">
      
      <li class="nav-item">
        <a class="nav-link js-search" href="#"><i class="fas fa-search" aria-hidden="true"></i></a>
      </li>
      

      
      <li class="nav-item">
        <a class="nav-link js-dark-toggle" href="#"><i class="fas fa-moon" aria-hidden="true"></i></a>
      </li>
      

      

    </ul>

  </div>
</nav>


  

<div class="container-fluid docs">
  <div class="row flex-xl-nowrap">
    <div class="col-12 col-md-3 col-xl-2 docs-sidebar">
      





  




<form class="docs-search d-flex align-items-center">
  <button class="btn docs-toggle d-md-none p-0 mr-3" type="button" data-toggle="collapse" data-target="#docs-nav" aria-controls="docs-nav" aria-expanded="false" aria-label="Toggle section navigation">
    <span><i class="fas fa-bars"></i></span>
  </button>

  
  <input name="q" type="search" class="form-control" placeholder="Search..." autocomplete="off">
  
</form>

<nav class="collapse docs-links" id="docs-nav">
  

  
  
  
  
  <div class="docs-toc-item">
    <a class="docs-toc-link" href="/courses/cours1/">Semantic Representations</a>
    <ul class="nav docs-sidenav">
      
      <li class="active">
        <a href="/courses/cours1/example1/">TP 1</a>
      </li>
      
      <li >
        <a href="/courses/cours1/example2/">TP 2</a>
      </li>
      
    </ul>
    

  </div>
  
  
</nav>

    </div>

    
    <div class="d-none d-xl-block col-xl-2 docs-toc">
      <ul class="nav toc-top">
        <li><a href="#" id="back_to_top" class="docs-toc-title">Contents</a></li>
      </ul>

      <nav id="TableOfContents"></nav>

      
    </div>
    

    <main class="col-12 col-md-9 col-xl-8 py-md-3 pl-md-5 docs-content" role="main">

      <article class="article">

        <div class="docs-article-container">
          <h1>Word embeddings training</h1>

          <div class="article-style">
            <p>[English version below]</p>
<h1 id="objectif">Objectif</h1>
<p>L'objectif du TP est de construire et de comparer différents type de plongements lexicaux (embeddings de mots) en utilisant les bibliothèques <code>gensim</code> et <code>fasttext</code>.<br>
Ces embeddings seront entrainés sur deux corpus différents : corpus en domaine médical (QUAERO_FrenchMed) de petit taille et un corpus non médical (QUAERO_FrenchPress) de grand taille.
Ils seront évaluer sur la tâche de détection d’entités nommées (NER : Named Entity recognition)  pendant le TP2 (l’après midi).</p>
<p>Vous êtes invités à utiliser les approches <strong>word2vec</strong> (Cbow, skipgram) et <strong>fasttext</strong> (Cbow).</p>
<h1 id="ressources">Ressources</h1>
<ul>
<li>Word2vec : <a href="https://radimrehurek.com/gensim/models/word2vec.html#gensim.models.word2vec.Word2Vec">https://radimrehurek.com/gensim/models/word2vec.html#gensim.models.word2vec.Word2Vec</a></li>
<li>Fasttext : <a href="https://fasttext.cc/docs/en/support.html">https://fasttext.cc/docs/en/support.html</a></li>
<li>Corpus: <a href="https://perso.limsi.fr/neveol/TP_ISD2020.zip">https://perso.limsi.fr/neveol/TP_ISD2020.zip</a>
<ul>
<li>Les fichiers <code>QUAERO_FrenchMed.ospl</code> et <code>QUAERO_FrenchPress_ID.ospl</code> seront utiliser pour l'apprentissage des embeddings. Ils contiennent des corpus au format «une phrase par ligne», avec une segmentation des tokens qui sont séparés par des espaces.</li>
</ul>
</li>
</ul>
<h1 id="outils-ncessaires">Outils nécessaires</h1>
<p>Avant de commencer le TP, Je vous invite à suivre les étapes suivantes pour installer les outils :</p>
<pre><code># Créer l'environnement de travail «miniconda»
# Télécharger le fichier et l'installer comme suit :
 wget https://repo.anaconda.com/miniconda/Miniconda3-latest-Linux-x86_64.sh
 chmod +x Miniconda3-latest-Linux-x86_64.sh
./Miniconda3-latest-Linux-x86_64.sh
# Créer l'environnement et l'activer
  conda create -n myenv python=3.6
  Conda activate myenv
# Installer les outils nécessaires pour la création de plongements lexicaux
  pip install gensim==0.12.0
  pip install fasttext 
</code></pre>
<h1 id="apprentissage-des-embeddings-de-mot">Apprentissage des embeddings de mot</h1>
<p>La première étape de votre travail va être de créer des scripts python et bash permettant d'apprendre les différentes approches d’embeddings <strong>word2vec</strong> (Cbow, skipgram) et <strong>fasttext</strong> (Cbow) sur les deux corpus médical et non médical <strong>QUAERO_FrenchMed</strong> et <strong>QUAERO_FrenchPress</strong> (au total 6 embeddings).</p>
<p>Suivez les étapes nécessaires dans la documentation pour créer et sauvegarder les modèles et les embeddings de mots.</p>
<p>Vous pouvez utiliser ces hyper-paramètres pour l'apprentissage des embeddings : <code>dim=100</code>, <code>min_count=1</code>.</p>
<h1 id="similarit-smantique">Similarité sémantique</h1>
<p>La deuxième étape consiste à trouver les mots les plus proches d'un mot donné en s'appuyant sur le calcul de similarité cosinus.
Plusieurs évaluations à faire :</p>
<ul>
<li>Comparer des  d'embeddings entrainés sur le même corpus :
<ul>
<li>tester l'impact des approches (skipgram, cbow, fasttext) sur le résultats</li>
</ul>
</li>
<li>Comparer des embeddings (même approche) entrainés sur de corpus différents (médical et non médical) :
<ul>
<li>tester l'impact de données (type et quantité) sur les résultats</li>
</ul>
</li>
</ul>
<p>Voici la liste de mots candidates :  <code>patient, traitement, maladie, solution, jaune</code></p>
<p>Pour l'évaluation vous pouvez utiliser soit :</p>
<ul>
<li>la méthode <code>spatial</code> de la bibliothèque python scipy, dans ce cas, vous devez charger les embeddings construits, et cherchez pour un mot donné la liste des 10 mots les plus proches</li>
<li>la méthode <code>most_similar</code> du gensim, dans ce cas, vous devez charger les modèles sauvegardés
<ul>
<li>vous pouvez utiliser gensim pour charger les modèles word2vec et fasttext</li>
</ul>
</li>
</ul>
<hr>
<h1 id="objective">Objective</h1>
<p>The objective of this lab session is to build and compare different word embeddings aproaches using the <code>gensim</code> and<code> fasttext</code> libraries.
These embeddings will be trained on two different corpora: a small medical corpus (QUAERO_FrenchMed) and a large non-medical corpus (QUAERO_FrenchPress).
They will be evaluated on the NER: Named Entity recognition task during the second pratical session TP2 (afternoon).</p>
<p>You are invited to use the <strong>word2vec</strong> (Cbow, skipgram) and <strong>fasttext</strong> (Cbow) approaches.</p>
<h1 id="ressources-1">Ressources</h1>
<ul>
<li>Word2vec : <a href="https://radimrehurek.com/gensim/models/word2vec.html#gensim.models.word2vec.Word2Vec">https://radimrehurek.com/gensim/models/word2vec.html#gensim.models.word2vec.Word2Vec</a></li>
<li>Fasttext : <a href="https://fasttext.cc/docs/en/support.html">https://fasttext.cc/docs/en/support.html</a></li>
<li>Corpus: <a href="https://perso.limsi.fr/neveol/TP_ISD2020.zip">https://perso.limsi.fr/neveol/TP_ISD2020.zip</a>
<ul>
<li>The files <code>QUAERO_FrenchMed.ospl</code> and<code> QUAERO_FrenchPress_ID.ospl</code> will be used for learning embeddings. They contain corpora in “one sentence per line” format, with a segmentation of the tokens which are separated by spaces.</li>
</ul>
</li>
</ul>
<h1 id="requirements">Requirements</h1>
<p>Before starting, I invite you to follow the next steps to install the tools:</p>
<pre><code># Create the &quot;miniconda&quot; environment
# Download the file and install it as follows:
 wget https://repo.anaconda.com/miniconda/Miniconda3-latest-Linux-x86_64.sh
 chmod +x Miniconda3-latest-Linux-x86_64.sh
./Miniconda3-latest-Linux-x86_64.sh
# Create the environment and activate it
  conda create -n myenv python=3.6
  Conda activate myenv
# Install the required tools to train word embeddings
  pip install gensim==0.12.0
  pip install fasttext 
</code></pre>
<h1 id="word-embeddings-training">Word embeddings training</h1>
<p>The first step of your work is to create python and bash scripts allowing you to train the different embeddings approaches: <strong>word2vec</strong> (Cbow, skipgram) and <strong>fasttext</strong> (Cbow), on the two medical and non-medical corpora, resulting to 6 embeddings models.</p>
<p>Follow the steps in the documentation to create and save the models and the word embeddings.</p>
<p>You can use these hyper-parameters to train the embeddings: <code>dim = 100</code>,<code> min_count = 1</code>.</p>
<h1 id="semantic-similarity">Semantic similarity</h1>
<p>The second step is to find the closest words to a given word based on the cosine similarity calculation.
Several evaluations to do:</p>
<ul>
<li>Compare embeddings trained on the same corpus:
<ul>
<li>to test the impact of the embeddings approaches (skipgram, cbow, fasttext) on the results</li>
</ul>
</li>
<li>Compare embeddings (same approach) trained on different corpora (medical and non-medical):
<ul>
<li>to test the impact of data (type and quantity) on the results</li>
</ul>
</li>
</ul>
<p>Here is the candidate word list: <code>patient, treatment, disease, solution, yellow</code></p>
<p>For the evaluation you can use either:</p>
<ul>
<li><code>spatial</code> method of the python scipy library, in this case, you must load the embeddings vectors, and search for a given word for the list of the 10 closest words</li>
<li>gensim's <code>most_similar</code> method, in this case you have to load the saved models
<ul>
<li>you can use gensim to load word2vec and fasttext models</li>
</ul>
</li>
</ul>

          </div>

          



          
          <div class="article-widget">
            
<div class="post-nav">
  
  
  
  <div class="post-nav-item">
    <div class="meta-nav">Next</div>
    <a href="/courses/cours1/example2/" rel="prev">Named entity recognition</a>
  </div>
  
</div>

          </div>
          
        </div>

        <div class="body-footer">
          <p>Last updated on Sep 9, 2020</p>

          





  
  

<p class="edit-page">
  <a href="https://github.com/gcushen/hugo-academic/edit/master/content/courses/Cours1/example1.md">
    <i class="fas fa-pen pr-2"></i>Edit this page
  </a>
</p>




          

        </div>

      </article>

      <footer class="site-footer">
  

  <p class="powered-by">
    

    Powered by the
    <a href="https://sourcethemes.com/academic/" target="_blank" rel="noopener">Academic theme</a> for
    <a href="https://gohugo.io" target="_blank" rel="noopener">Hugo</a>.

    
  </p>
</footer>


    </main>
  </div>
</div>


      

    
    

    
    
    
      <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.4.1/jquery.min.js" integrity="sha256-CSXorXvZcTkaix6Yvo6HppcZGetbYMGWSFlBw8HfCJo=" crossorigin="anonymous"></script>
      <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery.imagesloaded/4.1.4/imagesloaded.pkgd.min.js" integrity="sha256-lqvxZrPLtfffUl2G/e7szqSvPBILGbwmsGE1MKlOi0Q=" crossorigin="anonymous"></script>
      <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery.isotope/3.0.6/isotope.pkgd.min.js" integrity="sha256-CBrpuqrMhXwcLLUd5tvQ4euBHCdh7wGlDfNz8vbu/iI=" crossorigin="anonymous"></script>
      <script src="https://cdnjs.cloudflare.com/ajax/libs/fancybox/3.5.7/jquery.fancybox.min.js" integrity="sha256-yt2kYMy0w8AbtF89WXb2P1rfjcP/HTHLT7097U8Y5b8=" crossorigin="anonymous"></script>

      

      
        
        <script src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/9.15.10/highlight.min.js" integrity="sha256-1zu+3BnLYV9LdiY85uXMzii3bdrkelyp37e0ZyTAQh0=" crossorigin="anonymous"></script>
        
        <script src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/9.15.10/languages/r.min.js"></script>
        
      

      
      
    

    
    
      <script src="https://cdnjs.cloudflare.com/ajax/libs/leaflet/1.5.1/leaflet.js" integrity="sha256-EErZamuLefUnbMBQbsEqu1USa+btR2oIlCpBJbyD4/g=" crossorigin="anonymous"></script>
    

    
    
    <script>const code_highlighting = true;</script>
    

    
    
    
    
    
    
    <script>
      const search_config = {"indexURI":"/index.json","minLength":1,"threshold":0.3};
      const i18n = {"no_results":"No results found","placeholder":"Search...","results":"results found"};
      const content_type = {
        'post': "Posts",
        'project': "Projects",
        'publication' : "Publications",
        'talk' : "Talks"
        };
    </script>
    

    
    
    <script src="https://cdnjs.cloudflare.com/ajax/libs/anchor-js/4.1.1/anchor.min.js" integrity="sha256-pB/deHc9CGfFpJRjC43imB29Rse8tak+5eXqntO94ck=" crossorigin="anonymous"></script>
    <script>
      anchors.add();
    </script>
    

    
    
    <script id="search-hit-fuse-template" type="text/x-template">
      <div class="search-hit" id="summary-{{key}}">
      <div class="search-hit-content">
        <div class="search-hit-name">
          <a href="{{relpermalink}}">{{title}}</a>
          <div class="article-metadata search-hit-type">{{type}}</div>
          <p class="search-hit-description">{{snippet}}</p>
        </div>
      </div>
      </div>
    </script>
    

    
    
    <script src="https://cdnjs.cloudflare.com/ajax/libs/fuse.js/3.2.1/fuse.min.js" integrity="sha256-VzgmKYmhsGNNN4Ph1kMW+BjoYJM2jV5i4IlFoeZA9XI=" crossorigin="anonymous"></script>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/mark.js/8.11.1/jquery.mark.min.js" integrity="sha256-4HLtjeVgH0eIB3aZ9mLYF6E8oU5chNdjU6p6rrXpl9U=" crossorigin="anonymous"></script>
    

    
    

    
    

    
    
    
    
    
    
    
    
    
      
    
    
    
    
    <script src="/js/academic.min.3227ab49eed49815d1b4ba40154f74e7.js"></script>

    






  
  

  
<div id="modal" class="modal fade" role="dialog">
  <div class="modal-dialog">
    <div class="modal-content">
      <div class="modal-header">
        <h5 class="modal-title">Cite</h5>
        <button type="button" class="close" data-dismiss="modal" aria-label="Close">
          <span aria-hidden="true">&times;</span>
        </button>
      </div>
      <div class="modal-body">
        <pre><code class="tex hljs"></code></pre>
      </div>
      <div class="modal-footer">
        <a class="btn btn-outline-primary my-1 js-copy-cite" href="#" target="_blank">
          <i class="fas fa-copy"></i> Copy
        </a>
        <a class="btn btn-outline-primary my-1 js-download-cite" href="#" target="_blank">
          <i class="fas fa-download"></i> Download
        </a>
        <div id="modal-error"></div>
      </div>
    </div>
  </div>
</div>

</body>
</html>
