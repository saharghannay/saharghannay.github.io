[{"authors":["sahar"],"categories":null,"content":"Sahar Ghannay is an associate professor at Université Paris-Saclay, in the CNRS, LIMSI research center, since September 2018.\nShe received a PhD in Computer Science from Le Mans University on Septembre 2017. Her thesis work is part of the ANR VERA (AdVanced ERror Analysis for speech recognition) project. During her PhD, she spent a few months as @ visiting researcher at Apple within the Siri Speech team.\nAs a postdoctoral researcher at LIUM, she worked on neural end-to-end systems for the detection of named entities, speech understanding, as part of the Chist-Era M2CR (Multimodal Multilingual Continuous Representation for Human Language Understanding) project.\nHer main research interests are continuous representations learning and their application to natural language processing and speech recognition tasks. She is also interested in semantic textual similarity task and its application to dialog system.\n","date":-62135596800,"expirydate":-62135596800,"kind":"taxonomy","lang":"en","lastmod":-62135596800,"objectID":"004430b7d893eda84108a518741ff979","permalink":"https://saharghannay.github.io/authors/sahar/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/authors/sahar/","section":"authors","summary":"Sahar Ghannay is an associate professor at Université Paris-Saclay, in the CNRS, LIMSI research center, since September 2018.\nShe received a PhD in Computer Science from Le Mans University on Septembre 2017. Her thesis work is part of the ANR VERA (AdVanced ERror Analysis for speech recognition) project. During her PhD, she spent a few months as @ visiting researcher at Apple within the Siri Speech team.\nAs a postdoctoral researcher at LIUM, she worked on neural end-to-end systems for the detection of named entities, speech understanding, as part of the Chist-Era M2CR (Multimodal Multilingual Continuous Representation for Human Language Understanding) project.","tags":null,"title":"Sahar Ghannay","type":"authors"},{"authors":null,"categories":null,"content":"BSc level (L2) course, Université Paris-Saclay, IUT Orsay, Computer Science Department\n 2018-2020 BSc level (L2) Javascript, advanced javascript concepts, Ajax, JQuery  ","date":1599091200,"expirydate":-62135596800,"kind":"section","lang":"en","lastmod":1599091200,"objectID":"f9f8ab8322eb1af48e6412d73c4b1661","permalink":"https://saharghannay.github.io/courses/cours3/","publishdate":"2020-09-03T00:00:00Z","relpermalink":"/courses/cours3/","section":"courses","summary":"Course for  BSc level (L2) about Service client web programming Université Paris-Saclay, IUT Orsay, Computer Science Department","tags":null,"title":"Service client web programming","type":"docs"},{"authors":null,"categories":null,"content":"BSc level (L2) course, Université Paris-Saclay, IUT Orsay, Computer Science Department\n 2018-2020 BSc level (L2) PHP, MySQL queries, Object Oriented Programming, cookies, sessions  ","date":1599091200,"expirydate":-62135596800,"kind":"section","lang":"en","lastmod":1599091200,"objectID":"e94d51a746f8c97f17fe3dbae0560054","permalink":"https://saharghannay.github.io/courses/cours2/","publishdate":"2020-09-03T00:00:00Z","relpermalink":"/courses/cours2/","section":"courses","summary":"Course for  BSc level (L2) about Service side web programming Université Paris-Saclay, IUT Orsay, Computer Science Department","tags":null,"title":"Service side web programming","type":"docs"},{"authors":null,"categories":null,"content":"BSc level (L2, L3) course, PS, Le Mans University, Computer Science Department\n 2017-2018 BSc level (L2, L3) Basis of Prolog, facts, rules, unification, recursion, lists  ","date":1538697600,"expirydate":-62135596800,"kind":"section","lang":"en","lastmod":1538697600,"objectID":"ec416e9ab385ed7f30033a491221981d","permalink":"https://saharghannay.github.io/courses/cours8/","publishdate":"2018-10-05T00:00:00Z","relpermalink":"/courses/cours8/","section":"courses","summary":"Course for  BSc level (L2, L3) about logic programming at the Le Mans University, Computer Science Department","tags":null,"title":"Logic programming","type":"docs"},{"authors":null,"categories":null,"content":"Master 2 course , Université Paris-Saclay, IUT Orsay, Computer Science Department\n 2018-2020 MSc level (M2) Introduction to distributed representations, recent approaches, evaluation approaches In lab sessions, students will learn how to train word embeddings (TP1) and use them for named entity recognition (TP2)  ","date":1536105600,"expirydate":-62135596800,"kind":"section","lang":"en","lastmod":1599609600,"objectID":"05d9bc36ed262b9edea8d8add7453d44","permalink":"https://saharghannay.github.io/courses/cours1/","publishdate":"2018-09-05T00:00:00Z","relpermalink":"/courses/cours1/","section":"courses","summary":"Course for MSc level (M2) about semantic representations at the Université Paris-Saclay, IUT Orsay, Computer Science Department","tags":null,"title":"Semantic Representations","type":"docs"},{"authors":null,"categories":null,"content":"BSc level (L2) course, Université Paris-Saclay, IUT Orsay, Computer Science Department\n 2018-2020 BSc level (L1) SQL queries, function, procedure, trigger, cursors, packages  ","date":1517788800,"expirydate":-62135596800,"kind":"section","lang":"en","lastmod":1517788800,"objectID":"8762f93299e0c9200f94f4eee85f6154","permalink":"https://saharghannay.github.io/courses/cours4/","publishdate":"2018-02-05T00:00:00Z","relpermalink":"/courses/cours4/","section":"courses","summary":"Course for BSc level (L2) about database Université Paris-Saclay, IUT Orsay, Computer Science Department","tags":null,"title":"Database programming and administration","type":"docs"},{"authors":null,"categories":null,"content":"BSc level (L2) PS, Le Mans University, Computer Science Department\n 2014-2017 BSc level (L2) Data structures (linked list, hashtable, tree), pointers, recursivity  ","date":1412467200,"expirydate":-62135596800,"kind":"section","lang":"en","lastmod":1412467200,"objectID":"9a520a71f5e09c7774157148fed84026","permalink":"https://saharghannay.github.io/courses/cours6/","publishdate":"2014-10-05T00:00:00Z","relpermalink":"/courses/cours6/","section":"courses","summary":"Course for  BSc level (L2) about algorithmic and programming at the Le Mans University, Computer Science Department","tags":null,"title":"Algorithmic and programming","type":"docs"},{"authors":null,"categories":null,"content":"BSc level (L2, L3 (Engineering school)) PS, Le Mans University, Computer Science Department\n 2016-2018 BSc level (L2, L3 (Engineering school)) design of a relational database, implementation and operation of a database in SQL  ","date":1412467200,"expirydate":-62135596800,"kind":"section","lang":"en","lastmod":1412467200,"objectID":"dd0cb1de5b29127b809dc1ecac3f4711","permalink":"https://saharghannay.github.io/courses/cours7/","publishdate":"2014-10-05T00:00:00Z","relpermalink":"/courses/cours7/","section":"courses","summary":"Course for  BSc level (L2) about Database analysis and design at the Le Mans University, Computer Science Department","tags":null,"title":"Database analysis and design","type":"docs"},{"authors":null,"categories":null,"content":"BSc level (L1) practical session PS, Le Mans University, Computer Science Department\n 2014-2017 BSc level (L1) Algorithmics, variables, loops, functions  ","date":1412467200,"expirydate":-62135596800,"kind":"section","lang":"en","lastmod":1412467200,"objectID":"4dfe0b7677a6096fcd0a9393089aedfd","permalink":"https://saharghannay.github.io/courses/cours5/","publishdate":"2014-10-05T00:00:00Z","relpermalink":"/courses/cours5/","section":"courses","summary":"Course for  BSc level (L1) about C and python programming at the Le Mans University, Computer Science Department","tags":null,"title":"Introduction to programming C/python","type":"docs"},{"authors":null,"categories":null,"content":"[English version below]\nObjectif L'objectif du TP est de construire et de comparer différents type de plongements lexicaux (embeddings de mots) en utilisant les bibliothèques gensim et fasttext.\nCes embeddings seront entrainés sur deux corpus différents : corpus en domaine médical (QUAERO_FrenchMed) de petite taille et un corpus non médical (QUAERO_FrenchPress) de grande taille. Ils seront évalués sur la tâche de détection d’entités nommées (NER : Named Entity recognition) pendant le TP2 (l’après midi).\nVous êtes invités à utiliser les approches word2vec (Cbow, skipgram) et fasttext (Cbow).\nRessources  Word2vec : https://radimrehurek.com/gensim/models/word2vec.html#gensim.models.word2vec.Word2Vec Fasttext : https://fasttext.cc/docs/en/support.html Corpus: https://perso.limsi.fr/neveol/TP_ISD2020.zip  Les fichiers QUAERO_FrenchMed.ospl et QUAERO_FrenchPress_ID.ospl seront utilisés pour l'apprentissage des embeddings. Ils contiennent des corpus au format «une phrase par ligne», avec une segmentation des tokens qui sont séparés par des espaces.    Outils nécessaires Avant de commencer le TP, Je vous invite à suivre les étapes suivantes pour installer les outils :\n# Créer l'environnement de travail «miniconda» # Télécharger le fichier et l'installer comme suit : wget https://repo.anaconda.com/miniconda/Miniconda3-latest-Linux-x86_64.sh chmod +x Miniconda3-latest-Linux-x86_64.sh ./Miniconda3-latest-Linux-x86_64.sh # Créer l'environnement et l'activer conda create -n myenv python=3.6 Conda activate myenv # Installer les outils nécessaires pour la création de plongements lexicaux pip install gensim==0.12.0 pip install fasttext  Apprentissage des embeddings de mot La première étape de votre travail va être de créer des scripts python et bash permettant d'apprendre les différentes approches d’embeddings word2vec (Cbow, skipgram) et fasttext (Cbow) sur les deux corpus médical et non médical QUAERO_FrenchMed et QUAERO_FrenchPress (au total 6 embeddings).\nSuivez les étapes nécessaires dans la documentation pour créer et sauvegarder les modèles et les embeddings de mots.\nVous pouvez utiliser ces hyper-paramètres pour l'apprentissage des embeddings : dim=100, min_count=1.\nSimilarité sémantique La deuxième étape consiste à trouver les mots les plus proches d'un mot donné en s'appuyant sur le calcul de similarité cosinus. Plusieurs évaluations à faire :\n Comparer des d'embeddings entrainés sur le même corpus :  tester l'impact des approches (skipgram, cbow, fasttext) sur le résultats   Comparer des embeddings (même approche) entrainés sur de corpus différents (médical et non médical) :  tester l'impact de données (type et quantité) sur les résultats    Voici la liste de mots candidats : patient, traitement, maladie, solution, jaune\nPour l'évaluation vous pouvez utiliser soit :\n la méthode spatial de la bibliothèque python scipy, dans ce cas, vous devez charger les embeddings construits, et cherchez pour un mot donné la liste des 10 mots les plus proches la méthode most_similar du gensim, dans ce cas, vous devez charger les modèles sauvegardés  vous pouvez utiliser gensim pour charger les modèles word2vec et fasttext     Objective The objective of this lab session is to build and compare different word embeddings aproaches using the gensim and fasttext libraries. These embeddings will be trained on two different corpora: a small medical corpus (QUAERO_FrenchMed) and a large non-medical corpus (QUAERO_FrenchPress). They will be evaluated on the NER: Named Entity recognition task during the second pratical session TP2 (afternoon).\nYou are invited to use the word2vec (Cbow, skipgram) and fasttext (Cbow) approaches.\nRessources  Word2vec : https://radimrehurek.com/gensim/models/word2vec.html#gensim.models.word2vec.Word2Vec Fasttext : https://fasttext.cc/docs/en/support.html Corpus: https://perso.limsi.fr/neveol/TP_ISD2020.zip  The files QUAERO_FrenchMed.ospl and QUAERO_FrenchPress_ID.ospl will be used for learning embeddings. They contain corpora in “one sentence per line” format, with a segmentation of the tokens which are separated by spaces.    Requirements Before starting, I invite you to follow the next steps to install the tools:\n# Create the \u0026quot;miniconda\u0026quot; environment # Download the file and install it as follows: wget https://repo.anaconda.com/miniconda/Miniconda3-latest-Linux-x86_64.sh chmod +x Miniconda3-latest-Linux-x86_64.sh ./Miniconda3-latest-Linux-x86_64.sh # Create the environment and activate it conda create -n myenv python=3.6 Conda activate myenv # Install the required tools to train word embeddings pip install gensim==0.12.0 pip install fasttext  Word embeddings training The first step of your work is to create python and bash scripts allowing you to train the different embeddings approaches: word2vec (Cbow, skipgram) and fasttext (Cbow), on the two medical and non-medical corpora, resulting to 6 embeddings models.\nFollow the steps in the documentation to create and save the models and the word embeddings.\nYou can use these hyper-parameters to train the embeddings: dim = 100, min_count = 1.\nSemantic similarity The second step is to find the closest words to a given word based on the cosine similarity calculation. Several evaluations to do:\n Compare embeddings trained on the same corpus:  to test the impact of the embeddings approaches (skipgram, cbow, fasttext) on the results   Compare embeddings (same approach) trained on different corpora (medical and non-medical):  to test the impact of data (type and quantity) on the results    Here is the candidate word list: patient, treatment, disease, solution, yellow\nFor the evaluation you can use either:\n spatial method of the python scipy library, in this case, you must load the embeddings vectors, and search for a given word for the list of the 10 closest words gensim's most_similar method, in this case you have to load the saved models  you can use gensim to load word2vec and fasttext models    ","date":1525474800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1599609600,"objectID":"2c01261d506ea68504f64483d00a395f","permalink":"https://saharghannay.github.io/courses/cours1/example1/","publishdate":"2018-05-05T00:00:00+01:00","relpermalink":"/courses/cours1/example1/","section":"courses","summary":"[English version below]\nObjectif L'objectif du TP est de construire et de comparer différents type de plongements lexicaux (embeddings de mots) en utilisant les bibliothèques gensim et fasttext.\nCes embeddings seront entrainés sur deux corpus différents : corpus en domaine médical (QUAERO_FrenchMed) de petite taille et un corpus non médical (QUAERO_FrenchPress) de grande taille. Ils seront évalués sur la tâche de détection d’entités nommées (NER : Named Entity recognition) pendant le TP2 (l’après midi).","tags":null,"title":"Word embeddings training","type":"docs"},{"authors":null,"categories":null,"content":"[English version below]\nObjectif L'objectif du TP est de construire et de comparer différents modèles de reconnaissance d'entités nommées à partir des plongements lexicaux (embeddings) construits lors du TP 1. Nous utiliserons un modèle neuronal LSTM implémenté par Ma et Hovy\nVous êtes invités à construire plusieurs modèles pour chaque corpus de travail (voir ci-dessous) en faisant varier les paramètres suivants afin d’observer leur impact sur les performances de reconnaissance d’entités :\n taille du jeu d’entraînement ; taille du corpus utilisé pour créer les plongements lexicaux modèle des plongements lexicaux adéquation entre le domaine du corpus utilisé pour la reconnaissance d’entités et les plongements.  Ressources  L'outils https://github.com/XuezheMax/NeuroNLP2 Corpus: https://perso.limsi.fr/neveol/TP_ISD2020.zip  Outils nécessaires Veuillez installer cet outil dans votre environnement de travail.\n# Installer l'outil nécessaire pour la reconnaissance d'entités nommées git clone https://github.com/XuezheMax/NeuroNLP2.git pip install torch==1.6.0+cpu torchvision==0.7.0+cpu -f https://download.pytorch.org/whl/torch_stable.html pip install overrides pip uninstall scipy pip --no-cache-dir install scipy==1.1 cd NeuroNLP2 pip install .  Présentation rapide des corpus : Nous utiliserons deux corpus annotés en entités, l’un issu du domaine médical (QUAERO_FrenchMed) de petit taille et l'autre issu de la presse (QUAERO_FrenchPress) de plus grande taille.\nCes corpus vous sont fournis dans un format similaire au format conll : ils contiennent cinq colonnes séparées par des espaces.\nChaque mot correspond à une ligne et les phrases sont séparées par une ligne vide. Les colonnes correspondent dans l'ordre à l'index du mot dans la phrase, le mot, deux autres colonnes qui ne seront pas utilisées et la dernière colonne représente l'étiquette d'entité nommée.\nLes étiquettes d’entité nommée sont au format I-TYPE qui indique que le mot fait partie d’une entité de type TYPE. Si deux entités de même type se suivent, le premier mot de la seconde aura pour étiquette B-TYPE pour indiquer qu’il s'agit d’une nouvelle entité. L’étiquette O indique que le mot ne fait pas partie d’une entité.\nCréation de modèles La première étape de votre travail va être de créer des scripts shell permettant d’entraîner l'outil sous différentes configurations:\n Utiliser comme base de travail le script NeuroNLP2/experiments/scripts/run_ner_conll03.sh  Ajuster les paramètres concernant : le type de plongements, le fichier contenent votre vecteur de plongements, \u0026ndash;embedding_dict le répertoire de sortie désiré \u0026ndash;model_path , le corpus \u0026ndash;train \u0026ndash;dev \u0026ndash;test\n Pour les besoins du TP (temps de calcul des modèles), vous pouvez ajuster certains paramètres dans la configuration du modèle : diminuer le nombre d’epoch \u0026ndash;num_epochs 20, et de l’outil (script NeuroNLP2/experiments/ configs/ner/conll03.json ; par exemple, \u0026ldquo;crf\u0026rdquo;: false, \u0026ldquo;hidden_size\u0026rdquo;: 128, \u0026ldquo;out_features\u0026rdquo;: 64,).  Questions  Quel modèle obtient les meilleures performances sur chacun des corpus ? Voyez vous des différences entre les deux corpus ? Comparer ces résultats avec une méthode « baseline » simple à base de règles Pour cela, vous pourrez utiliser le script Perl NeuroNLP2/experiments/eval/conll03eval.v2  Pour aller plus loin :\n Comparer le corpus QUAERO_FrenchMed utilisé en TP avec celui distribué lors de la campagne CLEF eHealth 2016 : https://quaerofrenchmed.limsi.fr/ Constatez vous des différences ? Si oui, lesquelles ? Les résultats obtenus en TP peuvent-ils être comparés avec ceux obtenus lors de la campagne d’évaluation CLEF eHealth ? Pourquoi ?   Objective The objective of this lab session is to build and compare different models of named entity recognition using the word embeddings created during lab session 1. We will use the biLSTM model implemented by Ma and Hovy\nIn this lab session, you should attempt to create several models for each dataset (see below). You may observe the impact of the following parameters on anmed entity recognition performance:\n size of the training set ; size of the corpus used to create the word embeddings ; word embedding model ; consistency between the domain of the corpus used for entity recognition and the word embeddings.  Ressources  NER tool https://github.com/XuezheMax/NeuroNLP2 Corpus: https://perso.limsi.fr/neveol/TP_ISD2020.zip  Requirements Please install this tool in your conda environement.\n# Install the necessary tool for named entity recognition git clone https://github.com/XuezheMax/NeuroNLP2.git pip install torch==1.6.0+cpu torchvision==0.7.0+cpu -f https://download.pytorch.org/whl/torch_stable.html pip install overrides pip uninstall scipy pip --no-cache-dir install scipy==1.1 cd NeuroNLP2 pip install .  Quick overview of the datasets : We will use two datasets with named entity annotations : a small medical corpus (QUAERO_FrenchMed) and a larger news corpus (QUAERO_FrenchPress).\nThe datasets are provided in conll-like format and contain five columns separated by white spaces. Each word (or token) corresponds to a line and sentences are separated by an empty line.\nThe columns correspond to: the token index within the sentence, the token, two columns that will not be used in this lab and finally, the last column contains the named entity tag.\nNamed entity tags are in the I-TYPE format, which indicates that the word is part of a TYPE entity. If two entities follow each other, the first word of the second entity will get a B-TYPE tag to indicate that it is a new entity. The O tag indicates that the word is not part of an entity.\nNER models training The first step of your work will be to create shell scripts allowing you to train the tool in different configurations:\n Use the NeuroNLP2/experiments/scripts/run_ner_conll03.sh script as a working base  Adjust the parameters concerning: the type of embedding, the file contains your vector of embeddings, \u0026ndash;embedding_dict the desired output directory \u0026ndash;model_path, the corpus \u0026ndash;train \u0026ndash;dev \u0026ndash;test\n Du to time constraint, you can adjust certain parameters in the model configuration: decrease the number of epoch \u0026ndash;num_epochs 20, and of the tool (NeuroNLP2 script/experiments/configs/ner/conll03.json; for example, \u0026ldquo;crf\u0026rdquo;: false, \u0026ldquo;hidden_size\u0026rdquo;: 128, \u0026ldquo;out_features\u0026rdquo;: 64,).  Questions  Which model provides the best performance on each dataset? Are there differences between the datasets ? Compare the results of the models to a simple rule-based baseline method You may use this Perl script : NeuroNLP2/experiments/eval/conll03eval.v2  Going further :\n Compare the QUAERO_FrenchMed dataset used in this lab session with the one distributed in the CLEF eHealth 2016 shared task : https://quaerofrenchmed.limsi.fr/ Do you see any différence ? Please, describe. Can the results obtained in this lab session be directly compared to those of the CLEF eHealth shared task participants ? Please, explain.  ","date":1557010800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1557010800,"objectID":"f95e094aed92b488d1c8ae122805ac1d","permalink":"https://saharghannay.github.io/courses/cours1/example2/","publishdate":"2019-05-05T00:00:00+01:00","relpermalink":"/courses/cours1/example2/","section":"courses","summary":"[English version below]\nObjectif L'objectif du TP est de construire et de comparer différents modèles de reconnaissance d'entités nommées à partir des plongements lexicaux (embeddings) construits lors du TP 1. Nous utiliserons un modèle neuronal LSTM implémenté par Ma et Hovy\nVous êtes invités à construire plusieurs modèles pour chaque corpus de travail (voir ci-dessous) en faisant varier les paramètres suivants afin d’observer leur impact sur les performances de reconnaissance d’entités :","tags":null,"title":"Named entity recognition","type":"docs"},{"authors":["**Antoine Caubrière**","Sahar Ghannay","Nathalia Tomashenko","Renato De Mori","Emmanuel Morin","Yannick Estève"],"categories":null,"content":"","date":1588550400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1588550400,"objectID":"3e0101641539de073ce1b2ff0e190890","permalink":"https://saharghannay.github.io/publication/conference-paper/caubriere-2020-sluanaly/","publishdate":"2020-05-04T00:00:00Z","relpermalink":"/publication/conference-paper/caubriere-2020-sluanaly/","section":"publication","summary":"This paper presents a qualitative study of errors produced by an end-to-end spoken language understanding (SLU) system (speech signal to concepts) that reaches state of the art performance. Different studies are proposed to better understand the weaknesses of such systems: comparison to a classical pipeline SLU system, a study on the cause of concept deletions (the most frequent error), observation of a problem in the capability of the end-to-end SLU system to segment correctly concepts, analysis of the system behavior to process unseen concept/value pairs, analysis of the benefit of the curriculum-based transfer learning approach. Last, we proposed a way to compute embeddings of sub-sequences that seem to contain relevant information for future work.","tags":null,"title":"Error Analysis Applied to End-to-End Spoken Language Understanding","type":"publication"},{"authors":["**Sahar Ghannay**","Antoine Neuraz","Sophie Rosset"],"categories":null,"content":"","date":1588550400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1588550400,"objectID":"58a28f6eba3a0d1f4f3c61c9124d28c5","permalink":"https://saharghannay.github.io/publication/conference-paper/ghannay-2020-sluembed/","publishdate":"2020-05-04T00:00:00Z","relpermalink":"/publication/conference-paper/ghannay-2020-sluembed/","section":"publication","summary":"Word embeddings are shown to be a great asset for several Natural Language and Speech Processing tasks. While they are already evaluated on various NLP tasks, their evaluation on spoken or natural language understanding (SLU) is less studied. The goal of this study is two-fold: firstly, it focuses on semantic evaluation of common word embeddings approaches for SLU task; secondly, it investigates the use of two different data sets to train the embeddings: small and task-dependent corpus or huge and out-of-domain corpus. Experiments are carried out on 5 benchmark corpora (ATIS, SNIPS, SNIPS70, M2M, MEDIA), on which a relevance ranking was proposed in the literature. Interestingly, the performance of the embeddings is independent of the difficulty of the corpora. Moreover, the embeddings trained on huge and out-of-domain corpus yields to better results than the ones trained on small and task-dependent corpus.","tags":null,"title":"What is best for spoken language understanding: small but task-dependant embeddings or huge but out-of-domain embeddings?","type":"publication"},{"authors":["**Juan Manuel Coria**","Herv{'e} Bredin","Sahar Ghannay","Sophie Rosset"],"categories":null,"content":"","date":1585612800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1585612800,"objectID":"9dbe7026340b7f2b84e9b80d32d98130","permalink":"https://saharghannay.github.io/publication/conference-paper/juan-2020-spk/","publishdate":"2020-03-31T00:00:00Z","relpermalink":"/publication/conference-paper/juan-2020-spk/","section":"publication","summary":"Despite the growing popularity of metric learning approaches, very little work has attempted to perform a fair comparison of these techniques for speaker verification. We try to fill this gap and compare several metric learning loss functions in a systematic manner on the VoxCeleb dataset. The first family of loss functions is derived from the cross entropy loss (usually used for supervised classification) and includes the congenerous cosine loss, the additive angular margin loss, and the center loss. The second family of loss functions focuses on the similarity between training samples and includes the contrastive loss and the triplet loss. We show that the additive angular margin loss function outperforms all other loss functions in the study, while learning more robust representations. Based on a combination of SincNet trainable features and the x-vector architecture, the network used in this paper brings us a step closer to a really-end-to-end speaker verification system, when combined with the additive angular margin loss, while still being competitive with the x-vector baseline. In the spirit of reproducible research, we also release open source Python code for reproducing our results, and share pretrained PyTorch models on torch. hub that can be used either directly or after fine-tuning.","tags":null,"title":"A Comparison of Metric Learning Loss Functions for End-To-End Speaker Verification","type":"publication"},{"authors":["**Veron Mathilde**","Penas Anselmo","Echegoyen Guillermo","Banerjee Somnath","Ghannay Sahar"," Rosset Sophie"],"categories":null,"content":"","date":1585612800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1585612800,"objectID":"97619913663f05809ef96d43763bf126","permalink":"https://saharghannay.github.io/publication/conference-paper/mathilde_nldb_2020/","publishdate":"2020-03-31T00:00:00Z","relpermalink":"/publication/conference-paper/mathilde_nldb_2020/","section":"publication","summary":"In a long term exploitation environment, a Question Answering (QA) system should maintain or even improve its performance over time, trying to overcome the lacks made evident through the interactions with users. We claim that, in order to make progress in the QA over Knowledge Bases (KBs) research field, we must deal with two problems at the same time: the translation of Natural Language (NL) questions into formal queries, and the detection of missing knowledge that impact the way a question is answered. The research on these two challenges has not been addressed jointly until now, what motivates the main goals of this work: (i) the definition of the problem and (ii) the development of a methodology to create the evaluation resources needed to address this challenge.","tags":null,"title":"A Cooking Knowledge Graph and Benchmark for Question Answering Evaluation in Lifelong Learning Scenarios","type":"publication"},{"authors":["**Juan Manuel Coria**","Sahar Ghannay","Herv{'e} Bredin","Sophie Rosset"],"categories":null,"content":"","date":1585612800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1585612800,"objectID":"4653b2dfdbc02f3f446b90c90363ff27","permalink":"https://saharghannay.github.io/publication/conference-paper/juan-2020-metric/","publishdate":"2020-03-31T00:00:00Z","relpermalink":"/publication/conference-paper/juan-2020-metric/","section":"publication","summary":"The  task  of  automatic  misogyny  identifica-tion  and  categorization  has  not  received  asmuch attention as other natural language taskshave,  even  though  it  is  crucial  for  identify-ing hate speech in social Internet interactions.In  this  work,  we  address  this  sentence  clas-sification  task  from  a  representation  learningperspective, using both a bidirectional LSTMand BERT optimized with the following met-ric  learning  loss  functions:   contrastive  loss,triplet  loss,  center  loss,  congenerous  cosineloss and additive angular margin loss.  We setnew state-of-the-art for the task with our fine-tuned BERT, whose sentence embeddings canbe  compared  with  a  simple  cosine  distance,and we release all our code as open source foreasy reproducibility. Moreover, we find that al-most every loss function performs equally wellin this setting, matching the regular cross en-tropy loss.","tags":null,"title":"A Metric Learning Approach to Misogyny Categorization","type":"publication"},{"authors":["**Sahar Ghannay**","Yannick Estève","Nathalie Camelin"],"categories":null,"content":"","date":1583539200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1583539200,"objectID":"8adba8c05eb1037f429999144c517881","permalink":"https://saharghannay.github.io/publication/journal-article/ghannay-2020-spcom/","publishdate":"2020-03-07T00:00:00Z","relpermalink":"/publication/journal-article/ghannay-2020-spcom/","section":"publication","summary":"This paper presents a study of continuous word representations applied to automatic detection of speech recognition errors. A neural network architecture is proposed, which is well suited to handle continuous word representations, like word embeddings. We explore the use of several types of word representations: simple and combined linguistic embeddings, and acoustic ones associated to prosodic features, extracted from the audio signal. To compensate certain phenomena highlighted by the analysis of the error average span, we propose to model the errors at the sentence level through the use of sentence embeddings. An approach to build continuous sentence representations dedicated to ASR error detection is also proposed and compared to the Doc2vec approach. Experiments are performed on automatic transcriptions generated by the LIUM ASR system applied to the French ETAPE corpus. They show that the combination of linguistic embeddings, acoustic embeddings, prosodic features, and sentence embeddings in addition to more classical features yields very competitive results. Particularly, these results show the complementarity of acoustic embeddings and prosodic information, and show that the proposed sentence embeddings dedicated to ASR error detection achieve better results than generic sentence embeddings.","tags":null,"title":"A study of continuous space word and sentence representations applied to ASR error detection","type":"publication"},{"authors":["Mathilde Veron","**Ghannay Sahar**","Anne-Laure Ligozat","Sophie Rosset"],"categories":null,"content":"","date":1556064000,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1556064000,"objectID":"cc3a3d23840550d444170792baf1d14e","permalink":"https://saharghannay.github.io/publication/conference-paper/veron-2019-ll/","publishdate":"2019-04-24T00:00:00Z","relpermalink":"/publication/conference-paper/veron-2019-ll/","section":"publication","summary":"The main objective of this paper is to propose a functional definition of lifelong learning systems adapted to the framework of task-oriented dialogue sys- tems. We mainly identified two aspects where a lifelong learning technology could be applied in such systems: to improve the natural language understanding mod- ule and to enrich the database used by the system. Given our definition, we present an example of how it could be implemented in an existing task-oriented dialogue system that is developed in the LIHLITH project.","tags":null,"title":"Lifelong learning and task-oriented dialogue system: what does it mean?","type":"publication"},{"authors":[],"categories":[],"content":"Create slides in Markdown with Academic Academic | Documentation\n Features  Efficiently write slides in Markdown 3-in-1: Create, Present, and Publish your slides Supports speaker notes Mobile friendly slides   Controls  Next: Right Arrow or Space Previous: Left Arrow Start: Home Finish: End Overview: Esc Speaker notes: S Fullscreen: F Zoom: Alt + Click PDF Export: E   Code Highlighting Inline code: variable\nCode block:\nporridge = \u0026quot;blueberry\u0026quot; if porridge == \u0026quot;blueberry\u0026quot;: print(\u0026quot;Eating...\u0026quot;)   Math In-line math: $x + y = z$\nBlock math:\n$$ f\\left( x \\right) = ;\\frac{{2\\left( {x + 4} \\right)\\left( {x - 4} \\right)}}{{\\left( {x + 4} \\right)\\left( {x + 1} \\right)}} $$\n Fragments Make content appear incrementally\n{{% fragment %}} One {{% /fragment %}} {{% fragment %}} **Two** {{% /fragment %}} {{% fragment %}} Three {{% /fragment %}}  Press Space to play!\nOne  Two  Three \n A fragment can accept two optional parameters:\n class: use a custom style (requires definition in custom CSS) weight: sets the order in which a fragment appears   Speaker Notes Add speaker notes to your presentation\n{{% speaker_note %}} - Only the speaker can read these notes - Press `S` key to view {{% /speaker_note %}}  Press the S key to view the speaker notes!\n Only the speaker can read these notes Press S key to view    Themes  black: Black background, white text, blue links (default) white: White background, black text, blue links league: Gray background, white text, blue links beige: Beige background, dark text, brown links sky: Blue background, thin dark text, blue links    night: Black background, thick white text, orange links serif: Cappuccino background, gray text, brown links simple: White background, black text, blue links solarized: Cream-colored background, dark green text, blue links   Custom Slide Customize the slide style and background\n{{\u0026lt; slide background-image=\u0026quot;/img/boards.jpg\u0026quot; \u0026gt;}} {{\u0026lt; slide background-color=\u0026quot;#0000FF\u0026quot; \u0026gt;}} {{\u0026lt; slide class=\u0026quot;my-style\u0026quot; \u0026gt;}}   Custom CSS Example Let's make headers navy colored.\nCreate assets/css/reveal_custom.css with:\n.reveal section h1, .reveal section h2, .reveal section h3 { color: navy; }   Questions? Ask\nDocumentation\n","date":1549324800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1549324800,"objectID":"0e6de1a61aa83269ff13324f3167c1a9","permalink":"https://saharghannay.github.io/slides/example/","publishdate":"2019-02-05T00:00:00Z","relpermalink":"/slides/example/","section":"slides","summary":"An introduction to using Academic's Slides feature.","tags":[],"title":"Slides","type":"slides"},{"authors":["**Sahar Ghannay**","Antoine Caubrière","Yannick Estève","Nathalie Camelin","Edwin Simonnet","Antoine Laurent","Emmanuel Morin"],"categories":null,"content":"","date":1545091200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1545091200,"objectID":"daa858cf7c29c87471fa576fe359f4ef","permalink":"https://saharghannay.github.io/publication/conference-paper/ghannay-2018-endtoend/","publishdate":"2018-12-18T00:00:00Z","relpermalink":"/publication/conference-paper/ghannay-2018-endtoend/","section":"publication","summary":"Named entity recognition (NER) is among SLU tasks that usually extract semantic information from textual documents. Until now, NER from speech is made through a pipeline process that consists in processing first an automatic speech recognition (ASR) on the audio and then processing a NER on the ASR outputs. Such approach has some disadvantages (error propagation, metric to tune ASR systems sub-optimal in regards to the final task, reduced space search at the ASR output level,...) and it is known that more integrated ap- proaches outperform sequential ones, when they can be ap- plied. In this paper, we explore an end-to-end approach that directly extracts named entities from speech, though a unique neural architecture. On a such way, a joint optimization is possible for both ASR and NER. Experiments are carried on French data easily accessible, composed of data distributed in several evaluation campaigns. The results are promising since this end-to-end approach provides similar results (F- measure=0.66 on test data) than a classical pipeline approach to detect named entity categories (F-measure=0.64). Last, we also explore this approach applied to semantic concept extrac- tion, through a slot filling task known as a spoken language understanding problem.","tags":null,"title":"End-to-end named entity and semantic concept extraction from speech","type":"publication"},{"authors":null,"categories":null,"content":"Master 2 course, Université Paris-Saclay, IUT Orsay, Computer Science Department\n 2018-2020 MSc level (M2) Introduction to distributed representations, recent approaches, evaluation approaches  Practical session ","date":1538697600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1538697600,"objectID":"9d1a8705dadf2f02d80c6c86762f906c","permalink":"https://saharghannay.github.io/teachings/semantic-representations/","publishdate":"2018-10-05T00:00:00Z","relpermalink":"/teachings/semantic-representations/","section":"teachings","summary":"course for MSc level (M2) about semantic representations at the Université Paris-Saclay, IUT Orsay, Computer Science Department","tags":null,"title":"Semantic Representations","type":"teachings"},{"authors":["François Hernandez","Vincent Nguyen","**Sahar Ghannay**","Natalia Tomashenko","Yannick Estève"],"categories":null,"content":"","date":1537228800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1537228800,"objectID":"22dc6719c34d54a3ed83a677623c37b3","permalink":"https://saharghannay.github.io/publication/conference-paper/hernandez-2018-tedlium/","publishdate":"2018-09-18T00:00:00Z","relpermalink":"/publication/conference-paper/hernandez-2018-tedlium/","section":"publication","summary":"In this paper, we present TED-LIUM release 3 corpus3 ded- icated to speech recognition in English, which multiplies the available data to train acoustic models in comparison with TED-LIUM 2, by a factor of more than two. We present the recent development on Auto- matic Speech Recognition (ASR) systems in comparison with the two previous releases of the TED-LIUM Corpus from 2012 and 2014. We demonstrate that, passing from 207 to 452 hours of transcribed speech training data is really more useful for end-to-end ASR systems than for HMM-based state-of-the-art ones. This is the case even if the HMM- based ASR system still outperforms the end-to-end ASR system when the size of audio training data is 452 hours, with a Word Error Rate (WER) of 6.7% and 13.7%, respectively. Finally, we propose two repar- titions of the TED-LIUM release 3 corpus: the legacy repartition that is the same as that existing in release 2, and a new repartition, calibrated and designed to make experiments on speaker adaptation. Similar to the two first releases, TED-LIUM 3 corpus will be freely available for the research community.","tags":null,"title":"TED-LIUM 3: Twice as Much Data and Corpus Repartition for Experiments on Speaker Adaptation","type":"publication"},{"authors":null,"categories":null,"content":"BSc level (L2) course, Université Paris-Saclay, IUT Orsay, Computer Science Department\n 2018-2020 BSc level (L2) PHP, MySQL queries, Object Oriented Programming, cookies, sessions  ","date":1536105600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1536105600,"objectID":"e3bc9ae2e6862dc16b9d9107773df61c","permalink":"https://saharghannay.github.io/teachings/service-side-web-programming/","publishdate":"2018-09-05T00:00:00Z","relpermalink":"/teachings/service-side-web-programming/","section":"teachings","summary":"course for BSc level (L2) about semantic representations at the Université Paris-Saclay, IUT Orsay, Computer Science Department","tags":null,"title":"Service side web programming","type":"teachings"},{"authors":["**Sahar Ghannay**","Yannick Estève","Nathalie Camelin"],"categories":null,"content":"","date":1533168000,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1533168000,"objectID":"d7b2700c92bc2281dda2305092444a83","permalink":"https://saharghannay.github.io/publication/conference-paper/ghannay-2018-sentem/","publishdate":"2018-08-02T00:00:00Z","relpermalink":"/publication/conference-paper/ghannay-2018-sentem/","section":"publication","summary":"This paper presents a study on the modeling of automatic speech recognition errors at the sentence level. We aim in this study to compensate certain phenomena highlighted by the analysis of outputs generated by an ASR error detection system we pre- viously proposed. We investigated three different approaches, that are based respectively on the use of sentence embeddings dedicated to ASR error detection task, on a probabilistic con- textual model, and on a bidirectional long short-term memory (BLSTM) architecture. An approach to build task-specific sen- tence embeddings is proposed and compared to the Doc2vec approach. Experiments are performed on transcriptions gen- erated by the LIUM ASR system applied to the French ETAPE corpus. They show that the proposed sentence embeddings ded- icated to ASR error detection achieve better results than generic sentence embeddings, and that the integration of task-specific embeddings in our system achieves better results than the prob- abilistic contextual model and BLSTM models.","tags":null,"title":"Task Specific Sentence Embeddings for ASR Error Detection","type":"publication"},{"authors":["**Sahar Ghannay**","Yannick Estève","Nathalie Camelin"],"categories":null,"content":"","date":1528070400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1528070400,"objectID":"cbfd2c230589c81c9425bc1eabdbedec","permalink":"https://saharghannay.github.io/publication/conference-paper/ghannay-2018-sentemf/","publishdate":"2018-06-04T00:00:00Z","relpermalink":"/publication/conference-paper/ghannay-2018-sentemf/","section":"publication","summary":"This paper presents a study on the modeling of automatic speech recognition errors at the sentence level. We aim in this study to compensate certain phenomena highlighted by the analysis of the outputs generated by the ASR error detection system we previously proposed. We investigated three different approaches, that are based respectively on the use of sentence embeddings dedicated to ASR error detection task, a probabilistic contextual model (PCM) and a bidirectional long short term memory (BLSTM) architecture. An approach to build task-specific sentence embeddings is proposed and compared to the Doc2vec approach. Experiments are performed on transcriptions generated by the LIUM ASR system applied to the ETAPE corpus. They show that the proposed sentence embeddings dedicated to ASR error detection achieve better results than generic sentence embeddings, and that the integration of task-specific embeddings in our system achieves better results than the PCM and BLSTM models.","tags":null,"title":"Représentations de phrases dans un espace continu spécifiques à la tâche de détection d'erreurs","type":"publication"},{"authors":["Edwin Simonnet","**Sahar Ghannay**","Nathalie Camelin","Yannick Estève"],"categories":null,"content":"","date":1528070400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1528070400,"objectID":"665280f26d97eef03c027dbe1251a426","permalink":"https://saharghannay.github.io/publication/conference-paper/simonnet-2018-sluerrf/","publishdate":"2018-06-04T00:00:00Z","relpermalink":"/publication/conference-paper/simonnet-2018-sluerrf/","section":"publication","summary":"This paper presents an approach to simulate automatic speech recognition (ASR) errors from manual transcriptions and how it can be used to improve the performance of spoken language understanding (SLU) systems. The proposed method is based on the use of both acoustic and linguistic word embeddings in order to define a similarity measure between words. This measure is dedicated to predict ASR confusions. Actually, we assume that words acoustically and linguistically close are the ones confused by an ASR system. Experiments were carried on the French MEDIA corpus focusing on hotel reservation. They show that this approach significantly improves SLU system performance with a relative reduction of 21.2% of concept/value error rate (CVER), particularly when the SLU system is based on a neural approach (reduction of 22.4% of CVER). A comparison to a naive noising approach shows that the proposed noising approach is particularly relevant.","tags":null,"title":"Simulation d'erreurs de reconnaissance automatique dans un cadre de compréhension de la parole","type":"publication"},{"authors":["**Sahar Ghannay**","Antoine Caubrière","Yannick Estève","Antoine Laurent","Emmanuel Morin"],"categories":null,"content":"","date":1527638400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1527638400,"objectID":"f6d8b351a9d72a51bac7bca963c69845","permalink":"https://saharghannay.github.io/publication/conference-paper/ghannay-2018-endtoend2/","publishdate":"2018-05-30T00:00:00Z","relpermalink":"/publication/conference-paper/ghannay-2018-endtoend2/","section":"publication","summary":"Named entity recognition (NER) is among SLU tasks that usu- ally extract semantic information from textual documents. Un- til now, NER from speech is made through a pipeline process that consists in processing first an automatic speech recognition (ASR) on the audio and then processing a NER on the ASR outputs. Such approach has some disadvantages (error propa- gation, metric to tune ASR systems sub-optimal in regards to the final task, reduced space search at the ASR output level,...) and it is known that more integrated approaches outperform se- quential ones, when they can be applied. In this paper, we present a first study of end-to-end approach that directly ex- tracts named entities from speech, though a unique neural ar- chitecture. On a such way, a joint optimization is able for both ASR and NER. Experiments are carried on French data eas- ily accessible, composed of data distributed in several evalua- tion campaign. Experimental results show that this end-to-end approach provides better results (F-measure=0.69 on test data) than a classical pipeline approach to detect named entity cate- gories (F-measure=0.65).","tags":null,"title":"End-to-end named entity extraction from speech","type":"publication"},{"authors":["Edwin Simonnet","**Sahar Ghannay**","Nathalie Camelin","Yannick Estève"],"categories":null,"content":"","date":1525651200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1525651200,"objectID":"0e441e45a12a05528e09b9bcc94ac032","permalink":"https://saharghannay.github.io/publication/conference-paper/simonnet-2017-sluerr/","publishdate":"2018-05-07T00:00:00Z","relpermalink":"/publication/conference-paper/simonnet-2017-sluerr/","section":"publication","summary":"This paper presents an approach to simulate automatic speech recognition (ASR) errors from manual transcriptions and describes how it can be used to improve the performance of spoken language understanding (SLU) systems. In particular, we point out that this noising process is very usefull to obtain a more robust SLU system to ASR errors in case of insufficient training data or more if ASR transcriptions are not available during the training of the SLU model. The proposed method is based on the use of both acoustic and linguistic word embeddings in order to define a similarity measure between words dedicated to predict ASR confusions. Actually, we assume that words acoustically and linguistically close are the ones confused by an ASR system. By using this similarity measure in order to randomly substitute correct words by potentially confusing words in manual annotations used to train CRF- or neural based SLU systems, we augment the training corpus with these new noisy data. Experiments were carried on the French MEDIA corpus focusing on hotel reservation. They show that this approach significantly improves SLU system performance with a relative reduction of 21.2% of concept/value error rate (CVER), particularly when the SLU system is based on a neural approach (re- duction of 22.4% of CVER). A comparison to a naive noising approach shows that the proposed noising approach is particularly relevant.","tags":null,"title":"Simulating ASR errors for training SLU systems","type":"publication"},{"authors":["**Sahar Ghannay**","Yannick Estève","Nathalie Camelin"],"categories":null,"content":"","date":1508716800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1508716800,"objectID":"b8ca8391870a18c14d75a45016fd55de","permalink":"https://saharghannay.github.io/publication/conference-paper/ghannay-2017-enriching/","publishdate":"2017-10-23T00:00:00Z","relpermalink":"/publication/conference-paper/ghannay-2017-enriching/","section":"publication","summary":"The paper proposes a new approach for a posteriori enrichment of au- tomatic speech recognition (ASR) confusion networks (CNs). CNs are usually needed to decrease word error rate and to compute confidence measures, but they are also used in many ways in order to improve post-processing of ASR outputs. For instance, they can be helpfully used to propose alternative word hypotheses when ASR outputs are corrected by a human on post-edition. However, CNs bins do not have a fixed length, and sometimes contain only one or two word hypothe- ses: in this case the number of alternatives to correct a misrecognized word is very low, reducing the chance of helping the human annotator. Our approach for CN enrichment is based on a new similarity measure presented in this paper, computed from acoustic and linguistic word embeddings, that al- lows us to take into consideration both acoustic and linguistic similarities between two words. Experimental results show that our approach is relevant: enriched CNs (for a bin size equals to 6) increase the potential correction of erroneous words by 23% than initial CNs produced by an ASR system. In our experiments, a spoken language understanding task is also targeted.","tags":null,"title":"Enriching confusion networks for post-processing","type":"publication"},{"authors":["**Ghannay Sahar**"],"categories":null,"content":"","date":1506470400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1506470400,"objectID":"86617247d40207af807e8174129919b9","permalink":"https://saharghannay.github.io/publication/thesis/ghannay-2017-phd/","publishdate":"2017-09-27T00:00:00Z","relpermalink":"/publication/thesis/ghannay-2017-phd/","section":"publication","summary":"My thesis concerns a study of continuous word representations applied to the au- tomatic detection of speech recognition errors. Recent advances in the field of speech processing have led to significant improvements in speech recognition performances. However, recognition errors are still unavoidable. This reflects their sensitivity to the variability, e.g. to acoustic conditions, speaker, language style, etc. Our study focuses on the use of a neural approach to improve ASR error detection, using word embeddings. These representations have proven to be a great asset in various natural language processing tasks (NLP). The exploitation of continuous word representations is motivated by the fact that ASR error detection consists on locating the possible linguistic or acoustic in- congruities in automatic transcriptions. The aim is therefore to find the appropriate word representation which makes it possible to capture pertinent information in order to be able to detect these anomalies. Our contribution in this thesis concerns several initiatives. First, we start with a preliminary study in which we propose a neural architecture able to integrate different types of features, including word embeddings. Second, we propose a deep study of continuous word representations. This study focuses on the evaluation of different types of linguistic word embeddings and their combination in order to take advantage of their complementarities. On the other hand, it focuses on acoustic embeddings. The proposed approach relies on the use of a convolution neural network to build acoustic signal embeddings, and a deep neural network to build acoustic word embeddings. In addition, we propose two approaches to evaluate the performance of acoustic word embeddings. We also pro- pose to enrich the word representation, in input of the ASR error detection system, by prosodic features in addition to linguistic and acoustic embeddings. Integrating this information into our neural architecture provides a significant improvement in terms of classification error rate reduction in comparison to a conditional random field (CRF) based state-of-the-art approach. Then, we present a study on the analysis of classification errors, with the aim of perceiving the errors that are difficult to detect. Perspectives for improving the performance of our system are also proposed, by modelling the errors at the sen- tence level. Finally, we exploit the linguistic and acoustic embeddings as well as the information provided by our ASR error detection system in several downstream applications.","tags":null,"title":"A study of continuous word representations applied to the automatic detection of speech recognition errors","type":"publication"},{"authors":["Edwin Simonnet","**Sahar Ghannay**","Nathalie Camelin","Yannick Estève","Renato De Mori"],"categories":null,"content":"","date":1503187200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1503187200,"objectID":"5ddc8febabf47451ce0573d74c223e03","permalink":"https://saharghannay.github.io/publication/conference-paper/simonnet-2017-slu/","publishdate":"2017-08-20T00:00:00Z","relpermalink":"/publication/conference-paper/simonnet-2017-slu/","section":"publication","summary":"This paper addresses the problem of automatic speech recog- nition (ASR) error detection and their use for improving spo- ken language understanding (SLU) systems. In this study, the SLU task consists in automatically extracting, from ASR tran- scriptions, semantic concepts and concept/values pairs in a e.g touristic information system. An approach is proposed for en- riching the set of semantic labels with error specific labels and by using a recently proposed neural approach based on word embeddings to compute well calibrated ASR confidence mea- sures. Experimental results are reported showing that it is possi- ble to decrease significantly the Concept/Value Error Rate with a state of the art system, outperforming previously published re- sults performance on the same experimental data. It also shown that combining an SLU approach based on conditional random fields with a neural encoder/decoder attention based architec- ture, it is possible to effectively identifying confidence islands and uncertain semantic output segments useful for deciding appropriate error handling actions by the dialogue manager strategy.","tags":null,"title":"ASR Error Management for Improving Spoken Language Understanding","type":"publication"},{"authors":["**Sahar Ghannay**","Loïc Barrault"],"categories":null,"content":"","date":1493251200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1493251200,"objectID":"8605fba695834796cc8ab4f3cf647f6e","permalink":"https://saharghannay.github.io/publication/conference-paper/ghannay-2014-trans/","publishdate":"2017-04-27T00:00:00Z","relpermalink":"/publication/conference-paper/ghannay-2014-trans/","section":"publication","summary":"This paper describes the development op- erated into MANY, an open source sys- tem combination software based on con- fusion networks developed at LIUM. The hypotheses from Chinese-English MT sys- tems were combined with a new version of the software. MANY has been updated in order to use word confidence score and to boost n-grams occurring in input hypothe- ses. In this paper we propose either to use an adapted language model or adding some additional features in the decoder to boost certain n-grams probabilities. Ex- perimental results show that the updates yielded significant improvements in terms of BLEU score.","tags":null,"title":"Using Hypothesis Selection Based Features for Confusion Network MT System Combination","type":"publication"},{"authors":["**Sahar Ghannay**","Yannick Estève","Nathalie Camelin","Paule Deléglise"],"categories":null,"content":"","date":1473292800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1473292800,"objectID":"9ee53e30c6e3f42adb45d9d4f2d0a596","permalink":"https://saharghannay.github.io/publication/conference-paper/ghannay-2016-acoustic/","publishdate":"2016-09-08T00:00:00Z","relpermalink":"/publication/conference-paper/ghannay-2016-acoustic/","section":"publication","summary":"This paper focuses on error detection in Automatic Speech Recognition (ASR) outputs. A neural network architecture is proposed, which is well suited to handle continuous word rep- resentations, like word embeddings. In a previous study, the authors explored the use of linguistic word embeddings, and more particularly their combination. In this new study, the use of acoustic word embeddings is explored. Acoustic word em- beddings offer the opportunity of an a priori acoustic represen- tation of words that can be compared, in terms of similarity, to an embedded representation of the audio signal. First, we propose an approach to evaluate the intrinsic per- formances of acoustic word embeddings in comparison to orthographic representations in order to capture discriminative phonetic information. Since French language is targeted in experiments, a particular focus is made on homophone words. Then, the use of acoustic word embeddings is evaluated for ASR error detection. The proposed approach gets a classification error rate of 7.94% while the previous state-of-the-art CRF-based approach gets a CER of 8.56% on the outputs of the ASR system which won the ETAPE evaluation campaign on speech recognition of French broadcast news.","tags":null,"title":"Acoustic word embeddings for ASR error detection","type":"publication"},{"authors":["Yannick Estève","**Sahar Ghannay**","Nathalie Camelin"],"categories":null,"content":"","date":1472515200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1472515200,"objectID":"eaa734af2b528555fc88f061c9bf1a8c","permalink":"https://saharghannay.github.io/publication/conference-paper/esteve-2016-imp/","publishdate":"2016-08-30T00:00:00Z","relpermalink":"/publication/conference-paper/esteve-2016-imp/","section":"publication","summary":"Automatic speech recognition(ASR) offers the ability to access the semantic content present in spoken language within audio and video documents. While acoustic models based on deep neural networks have recently significantly improved the performances of ASR sys- tems, automatic transcriptions still contain errors. Errors perturb the exploitation of these ASR outputs by introducing noise to the text. To reduce this noise, it is possible to apply an ASR error detection in order to remove recognized words labelled as errors. This paper presents an approach that reaches very good results, better than previous state-of-the-art approaches. This work is based on a neural approach, and more especially on a study targeted to acoustic and linguistic word embeddings, that are representations of words in a continuous space. In comparison to the previous state-of-the-art approach which were based on Conditional Random Fields, our approach reduces the classification error rate by 7.2%.","tags":null,"title":"Recent improvements on error detection for automatic speech recognition","type":"publication"},{"authors":["**Sahar Ghannay**","Yannick Estève","Nathalie Camelin","Paule Deléglise"],"categories":null,"content":"","date":1471305600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1471305600,"objectID":"cd4fff3e423cd801a0aee78d2f48ac33","permalink":"https://saharghannay.github.io/publication/conference-paper/ghannay-2016-acouseval/","publishdate":"2016-08-16T00:00:00Z","relpermalink":"/publication/conference-paper/ghannay-2016-acouseval/","section":"publication","summary":"Recently, researchers in speech recogni- tion have started to reconsider using whole words as the basic modeling unit, instead of phonetic units. These systems rely on a function that embeds an arbitrary or fixed dimensional speech segments to a vec- tor in a fixed-dimensional space, named acoustic word embedding. Thus, speech segments of words that sound similarly will be projected in a close area in a con- tinuous space. This paper focuses on the evaluation of acoustic word embed- dings. We propose two approaches to eval- uate the intrinsic performances of acoustic word embeddings in comparison to ortho- graphic representations in order to eval- uate whether they capture discriminative phonetic information. Since French lan- guage is targeted in experiments, a partic- ular focus is made on homophone words.","tags":null,"title":"Evaluation of acoustic word embeddings","type":"publication"},{"authors":["**Sahar Ghannay**","Yannick Estève","Nathalie Camelin","Camille Dutrey","Fabian Santiago","Martine Adda-Decker"],"categories":null,"content":"","date":1467590400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1467590400,"objectID":"398e9f2790caaa08f168e0cb85673aa7","permalink":"https://saharghannay.github.io/publication/conference-paper/ghannay-2016-errprossf/","publishdate":"2016-07-04T00:00:00Z","relpermalink":"/publication/conference-paper/ghannay-2016-errprossf/","section":"publication","summary":"Recent advances in continuous word representation have been successfully used in several natural language processing tasks. This paper focuses on error prediction in Automatic Speech Recogni- tion (ASR) outputs and proposes to investigate the use of continuous word representation (word embeddings) within a neural network architecture. The main contribution of this paper is about word embeddings combination : several combination approaches are proposed in order to take advantage of their complementarity. The use of prosodic features, in addition to classical syntactic ones, is evaluated. Experiments are made on automatic transcriptions generated by the LIUM ASR system applied on the ETAPE corpus. They show that the proposed neural architecture, using an effective continuous word representation combination and prosodic features as additional features, outperforms significantly state-of-the-art approach based on the use of Conditional Random Fields. Last, the proposed system produces a well calibrated confidence measure, evaluated in terms of NCE.","tags":null,"title":"Utilisation des représentations continues des mots et des paramètres prosodiques pour la détection d'erreurs dans les transcriptions automatiques de la parole","type":"publication"},{"authors":["**Sahar Ghannay**","Benoit Favre","Yannick Estève","Nathalie Camelin"],"categories":null,"content":"","date":1463961600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1463961600,"objectID":"e8d3d7e9493b4612ae163faf73e4e095","permalink":"https://saharghannay.github.io/publication/conference-paper/ghannay-2016-weevaluation/","publishdate":"2016-05-23T00:00:00Z","relpermalink":"/publication/conference-paper/ghannay-2016-weevaluation/","section":"publication","summary":"Word embeddings have been successfully used in several natural language processing tasks (NLP) and speech processing. Different approaches have been introduced to calculate word embeddings through neural networks. In the literature, many studies focused on word embedding evaluation, but for our knowledge, there are still some gaps. This paper presents a study focusing on a rigorous comparison of the performances of different kinds of word embeddings. These performances are evaluated on different NLP and linguistic tasks, while all the word embeddings are estimated on the same training data using the same vocabulary, the same number of dimensions, and other similar characteristics. The evaluation results reported in this paper match those in the literature, since they point out that the improvements achieved by a word embedding in one task are not consistently observed across all tasks. For that reason, this paper investigates and evaluates approaches to combine word embeddings in order to take advantage of their complementarity, and to look for the effective word embeddings that can achieve good performances on all tasks. As a conclusion, this paper provides new perceptions of intrinsic qualities of the famous word embedding families, which can be different from the ones provided by works previously published in the scientific literature.","tags":null,"title":"Word embedding evaluation and combination","type":"publication"},{"authors":null,"categories":null,"content":"","date":1461715200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1461715200,"objectID":"d1311ddf745551c9e117aa4bb7e28516","permalink":"https://saharghannay.github.io/project/external-project/","publishdate":"2016-04-27T00:00:00Z","relpermalink":"/project/external-project/","section":"project","summary":"An example of linking directly to an external project website using `external_link`.","tags":["Demo"],"title":"External Project","type":"project"},{"authors":null,"categories":null,"content":"Lorem ipsum dolor sit amet, consectetur adipiscing elit. Duis posuere tellus ac convallis placerat. Proin tincidunt magna sed ex sollicitudin condimentum. Sed ac faucibus dolor, scelerisque sollicitudin nisi. Cras purus urna, suscipit quis sapien eu, pulvinar tempor diam. Quisque risus orci, mollis id ante sit amet, gravida egestas nisl. Sed ac tempus magna. Proin in dui enim. Donec condimentum, sem id dapibus fringilla, tellus enim condimentum arcu, nec volutpat est felis vel metus. Vestibulum sit amet erat at nulla eleifend gravida.\nNullam vel molestie justo. Curabitur vitae efficitur leo. In hac habitasse platea dictumst. Sed pulvinar mauris dui, eget varius purus congue ac. Nulla euismod, lorem vel elementum dapibus, nunc justo porta mi, sed tempus est est vel tellus. Nam et enim eleifend, laoreet sem sit amet, elementum sem. Morbi ut leo congue, maximus velit ut, finibus arcu. In et libero cursus, rutrum risus non, molestie leo. Nullam congue quam et volutpat malesuada. Sed risus tortor, pulvinar et dictum nec, sodales non mi. Phasellus lacinia commodo laoreet. Nam mollis, erat in feugiat consectetur, purus eros egestas tellus, in auctor urna odio at nibh. Mauris imperdiet nisi ac magna convallis, at rhoncus ligula cursus.\nCras aliquam rhoncus ipsum, in hendrerit nunc mattis vitae. Duis vitae efficitur metus, ac tempus leo. Cras nec fringilla lacus. Quisque sit amet risus at ipsum pharetra commodo. Sed aliquam mauris at consequat eleifend. Praesent porta, augue sed viverra bibendum, neque ante euismod ante, in vehicula justo lorem ac eros. Suspendisse augue libero, venenatis eget tincidunt ut, malesuada at lorem. Donec vitae bibendum arcu. Aenean maximus nulla non pretium iaculis. Quisque imperdiet, nulla in pulvinar aliquet, velit quam ultrices quam, sit amet fringilla leo sem vel nunc. Mauris in lacinia lacus.\nSuspendisse a tincidunt lacus. Curabitur at urna sagittis, dictum ante sit amet, euismod magna. Sed rutrum massa id tortor commodo, vitae elementum turpis tempus. Lorem ipsum dolor sit amet, consectetur adipiscing elit. Aenean purus turpis, venenatis a ullamcorper nec, tincidunt et massa. Integer posuere quam rutrum arcu vehicula imperdiet. Mauris ullamcorper quam vitae purus congue, quis euismod magna eleifend. Vestibulum semper vel augue eget tincidunt. Fusce eget justo sodales, dapibus odio eu, ultrices lorem. Duis condimentum lorem id eros commodo, in facilisis mauris scelerisque. Morbi sed auctor leo. Nullam volutpat a lacus quis pharetra. Nulla congue rutrum magna a ornare.\nAliquam in turpis accumsan, malesuada nibh ut, hendrerit justo. Cum sociis natoque penatibus et magnis dis parturient montes, nascetur ridiculus mus. Quisque sed erat nec justo posuere suscipit. Donec ut efficitur arcu, in malesuada neque. Nunc dignissim nisl massa, id vulputate nunc pretium nec. Quisque eget urna in risus suscipit ultricies. Pellentesque odio odio, tincidunt in eleifend sed, posuere a diam. Nam gravida nisl convallis semper elementum. Morbi vitae felis faucibus, vulputate orci placerat, aliquet nisi. Aliquam erat volutpat. Maecenas sagittis pulvinar purus, sed porta quam laoreet at.\n","date":1461715200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1461715200,"objectID":"8f66d660a9a2edc2d08e68cc30f701f7","permalink":"https://saharghannay.github.io/project/internal-project/","publishdate":"2016-04-27T00:00:00Z","relpermalink":"/project/internal-project/","section":"project","summary":"An example of using the in-built project page.","tags":["Deep Learning"],"title":"Internal Project","type":"project"},{"authors":["**Sahar Ghannay**","Yannick Estève","Nathalie Camelin","Camille Dutrey","Fabian Santiago","Martine Adda-Decker"],"categories":null,"content":"","date":1448323200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1448323200,"objectID":"eb168a3745cae9c371b0f34b0ffd0c37","permalink":"https://saharghannay.github.io/publication/conference-paper/ghannay-2015-errpross/","publishdate":"2015-11-24T00:00:00Z","relpermalink":"/publication/conference-paper/ghannay-2015-errpross/","section":"publication","summary":"Recent advances in continuous word representation have been successfully used in several natural language processing tasks. This pa- per focuses on error prediction in Automatic Speech Recognition (ASR) outputs and proposes to investigate the use of continuous word repre- sentation (word embeddings) within a neural network architecture. The main contribution of this paper is about word embeddings combi- nation: several combination approaches are proposed in order to take advantage of their complementarity. The use of prosodic features, in addition to classical syntactic ones, is evaluated. Experiments are made on automatic transcriptions generated by the LIUM ASR system applied on the ETAPE corpus. They show that the proposed neural architecture, using an effective continuous word rep- resentation combination and prosodic features as additional features, outperforms significantly state-of-the-art approach based on the use of Conditional Random Fields. Last, the proposed system produces a well calibrated confidence measure, evaluated in terms of Normalized Cross Entropy.","tags":null,"title":"Combining continous word representation and prosodic features for ASR error prediction","type":"publication"},{"authors":["**Sahar Ghannay**","Nathalie Camelin","Yannick Estève"],"categories":null,"content":"","date":1441929600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1441929600,"objectID":"f2d4c317d584f362fc1784273163fd24","permalink":"https://saharghannay.github.io/publication/conference-paper/ghannay-2015-erranalyse/","publishdate":"2015-09-11T00:00:00Z","relpermalink":"/publication/conference-paper/ghannay-2015-erranalyse/","section":"publication","summary":"In this paper, we focus on error detection in Automatic Speech Recognition (ASR) outputs. We present a new ap- proach using continuous word representation (word embed- dings) through a neural network classifier. This classifier is in charge to attribute a label (error or correct ) for each word within an ASR hypothesis. Combining with word embeddings, inputs are based on a set of features (ASR confidence scores, lexical, and syntactic features, including contextual information from each word). Experiments were conducted on the automatic transcrip- tions generated by the LIUM ASR system applied on the ETAPE corpus (French broadcast news). They show that the proposed neural architecture outperforms the state-of-the- art approach based on the use of Conditional Random Fields (CRF). Particularly in this study, we are interested in the analysis of the classifier outputs, in order to perceive the errors that are hard to detect. Results of this analysis are presented in this paper, providing useful information in order to improve the proposed ASR error detection system.","tags":null,"title":"Which ASR errors are hard to detect?","type":"publication"},{"authors":["**Sahar Ghannay**","Yannick Estève","Nathalie Camelin"],"categories":null,"content":"","date":1440979200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1440979200,"objectID":"d44609281f9f605fbd902cc32f23ff39","permalink":"https://saharghannay.github.io/publication/conference-paper/ghannay-2015-wecomberr/","publishdate":"2015-08-31T00:00:00Z","relpermalink":"/publication/conference-paper/ghannay-2015-wecomberr/","section":"publication","summary":"This study focuses on error detection in Automatic Speech Recognition (ASR) output. We propose to build a confidence classifier based on a neural network architecture, which is in charge to attribute a label (error or correct) for each word within an ASR hypothesis. This classifier uses word embed- dings as inputs, in addition to ASR confidence-based, lexical and syntactic features. We propose to evaluate the impact of three different kinds of word embeddings on this error de- tection approach, and we present a solution to combine these three different types of word embeddings in order to take ad- vantage of their complementarity. In our experiments, different approaches are evaluated on the automatic transcriptions generated by two different ASR systems applied on the ETAPE corpus (French broadcast news). Experimental results show that the proposed neural architectures achieve a CER reduction comprised between 4% and 5.8% in error detection, depending on test dataset, in comparison with a state-of-the-art CRF approach.","tags":null,"title":"Word embeddings combination and neural networks for robustness in ASR error detection","type":"publication"},{"authors":null,"categories":null,"content":" 2010-2015 (55 hours) BSc level (L2) Data structures (linked list, hashtable, tree), pointers, recursivity  ","date":-62135596800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":-62135596800,"objectID":"4fba0db4627d059e37fe8245553637cc","permalink":"https://saharghannay.github.io/project/cour-tranduction/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/project/cour-tranduction/","section":"project","summary":"BSc level (L2) course","tags":null,"title":"Algorithmic and programming","type":"project"}]