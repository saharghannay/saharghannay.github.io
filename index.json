[{"authors":["sahar"],"categories":null,"content":"Sahar Ghannay is an associate professor at Université Paris-Saclay, in the CNRS, LISN research center, since September 2018.\nShe received a PhD in Computer Science from Le Mans University on Septembre 2017. Her thesis work is part of the ANR VERA (AdVanced ERror Analysis for speech recognition) project. During her PhD, she spent a few months as a visiting researcher at Apple within the Siri Speech team.\nAs a postdoctoral researcher at LIUM, she worked on neural end-to-end systems for the detection of named entities, speech understanding, as part of the Chist-Era M2CR (Multimodal Multilingual Continuous Representation for Human Language Understanding) project.\nHer main research interests are continuous representations learning and their application to natural language processing and speech recognition tasks, semantic information extraction form spoken and writen language and dialog system.\n","date":-62135596800,"expirydate":-62135596800,"kind":"term","lang":"en","lastmod":-62135596800,"objectID":"004430b7d893eda84108a518741ff979","permalink":"https://saharghannay.github.io/authors/sahar/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/authors/sahar/","section":"authors","summary":"Sahar Ghannay is an associate professor at Université Paris-Saclay, in the CNRS, LISN research center, since September 2018.\nShe received a PhD in Computer Science from Le Mans University on Septembre 2017. Her thesis work is part of the ANR VERA (AdVanced ERror Analysis for speech recognition) project. During her PhD, she spent a few months as a visiting researcher at Apple within the Siri Speech team.\nAs a postdoctoral researcher at LIUM, she worked on neural end-to-end systems for the detection of named entities, speech understanding, as part of the Chist-Era M2CR (Multimodal Multilingual Continuous Representation for Human Language Understanding) project.","tags":null,"title":"Sahar Ghannay","type":"authors"},{"authors":null,"categories":null,"content":"BSc level (L2) course, Université Paris-Saclay, IUT Orsay, Computer Science Department\n2018-2020 BSc level (L2) Javascript, advanced javascript concepts, Ajax, JQuery ","date":1599091200,"expirydate":-62135596800,"kind":"section","lang":"en","lastmod":1599091200,"objectID":"f9f8ab8322eb1af48e6412d73c4b1661","permalink":"https://saharghannay.github.io/courses/cours3/","publishdate":"2020-09-03T00:00:00Z","relpermalink":"/courses/cours3/","section":"courses","summary":"Course for  BSc level (L2) about Service client web programming Université Paris-Saclay, IUT Orsay, Computer Science Department","tags":null,"title":"Service client web programming","type":"docs"},{"authors":null,"categories":null,"content":"BSc level (L2) course, Université Paris-Saclay, IUT Orsay, Computer Science Department\n2018-2020 BSc level (L2) PHP, MySQL queries, Object Oriented Programming, cookies, sessions ","date":1599091200,"expirydate":-62135596800,"kind":"section","lang":"en","lastmod":1599091200,"objectID":"e94d51a746f8c97f17fe3dbae0560054","permalink":"https://saharghannay.github.io/courses/cours2/","publishdate":"2020-09-03T00:00:00Z","relpermalink":"/courses/cours2/","section":"courses","summary":"Course for  BSc level (L2) about Service side web programming Université Paris-Saclay, IUT Orsay, Computer Science Department","tags":null,"title":"Service side web programming","type":"docs"},{"authors":null,"categories":null,"content":"BSc level (L2, L3) course, PS, Le Mans University, Computer Science Department\n2017-2018 BSc level (L2, L3) Basis of Prolog, facts, rules, unification, recursion, lists ","date":1538697600,"expirydate":-62135596800,"kind":"section","lang":"en","lastmod":1538697600,"objectID":"ec416e9ab385ed7f30033a491221981d","permalink":"https://saharghannay.github.io/courses/cours8/","publishdate":"2018-10-05T00:00:00Z","relpermalink":"/courses/cours8/","section":"courses","summary":"Course for  BSc level (L2, L3) about logic programming at the Le Mans University, Computer Science Department","tags":null,"title":"Logic programming","type":"docs"},{"authors":null,"categories":null,"content":"Master 2 course , Université Paris-Saclay, IUT Orsay, Computer Science Department\n2018-2025 MSc level (M2) Introduction to distributed representations, recent approaches, evaluation approaches In lab sessions, students will learn how to train and evaluate word embeddings (TP1) and use the word embeddings and trasformers models for named entity recognition (TP2) ","date":1536105600,"expirydate":-62135596800,"kind":"section","lang":"en","lastmod":1599609600,"objectID":"05d9bc36ed262b9edea8d8add7453d44","permalink":"https://saharghannay.github.io/courses/cours1/","publishdate":"2018-09-05T00:00:00Z","relpermalink":"/courses/cours1/","section":"courses","summary":"Course for MSc level (M2) about semantic representations at the Université Paris-Saclay, IUT Orsay, Computer Science Department","tags":null,"title":"Semantic Representations","type":"docs"},{"authors":null,"categories":null,"content":"BSc level (L2) course, Université Paris-Saclay, IUT Orsay, Computer Science Department\n2018-2020 BSc level (L1) SQL queries, function, procedure, trigger, cursors, packages ","date":1517788800,"expirydate":-62135596800,"kind":"section","lang":"en","lastmod":1517788800,"objectID":"8762f93299e0c9200f94f4eee85f6154","permalink":"https://saharghannay.github.io/courses/cours4/","publishdate":"2018-02-05T00:00:00Z","relpermalink":"/courses/cours4/","section":"courses","summary":"Course for BSc level (L2) about database Université Paris-Saclay, IUT Orsay, Computer Science Department","tags":null,"title":"Database programming and administration","type":"docs"},{"authors":null,"categories":null,"content":"BSc level (L2) PS, Le Mans University, Computer Science Department\n2014-2017 BSc level (L2) Data structures (linked list, hashtable, tree), pointers, recursivity ","date":1412467200,"expirydate":-62135596800,"kind":"section","lang":"en","lastmod":1412467200,"objectID":"9a520a71f5e09c7774157148fed84026","permalink":"https://saharghannay.github.io/courses/cours6/","publishdate":"2014-10-05T00:00:00Z","relpermalink":"/courses/cours6/","section":"courses","summary":"Course for  BSc level (L2) about algorithmic and programming at the Le Mans University, Computer Science Department","tags":null,"title":"Algorithmic and programming","type":"docs"},{"authors":null,"categories":null,"content":"BSc level (L2, L3 (Engineering school)) PS, Le Mans University, Computer Science Department\n2016-2018 BSc level (L2, L3 (Engineering school)) design of a relational database, implementation and operation of a database in SQL ","date":1412467200,"expirydate":-62135596800,"kind":"section","lang":"en","lastmod":1412467200,"objectID":"dd0cb1de5b29127b809dc1ecac3f4711","permalink":"https://saharghannay.github.io/courses/cours7/","publishdate":"2014-10-05T00:00:00Z","relpermalink":"/courses/cours7/","section":"courses","summary":"Course for  BSc level (L2) about Database analysis and design at the Le Mans University, Computer Science Department","tags":null,"title":"Database analysis and design","type":"docs"},{"authors":null,"categories":null,"content":"BSc level (L1) practical session PS, Le Mans University, Computer Science Department\n2014-2017 BSc level (L1) Algorithmics, variables, loops, functions ","date":1412467200,"expirydate":-62135596800,"kind":"section","lang":"en","lastmod":1412467200,"objectID":"4dfe0b7677a6096fcd0a9393089aedfd","permalink":"https://saharghannay.github.io/courses/cours5/","publishdate":"2014-10-05T00:00:00Z","relpermalink":"/courses/cours5/","section":"courses","summary":"Course for  BSc level (L1) about C and python programming at the Le Mans University, Computer Science Department","tags":null,"title":"Introduction to programming C/python","type":"docs"},{"authors":null,"categories":null,"content":"[English version below]\nObjectif L\u0026rsquo;objectif du TP est de construire et de comparer différents type de plongements lexicaux (embeddings de mots) en utilisant les bibliothèques gensim et fasttext.\nCes embeddings seront entrainés sur deux corpus différents : corpus en domaine médical (QUAERO_FrenchMed) de petite taille et un corpus non médical (QUAERO_FrenchPress) de grande taille. Ils seront évalués sur la tâche de détection d’entités nommées (NER : Named Entity recognition) pendant le TP2 (l’après midi).\nVous êtes invités à utiliser les approches word2vec (Cbow, skipgram) et fasttext (Cbow).\nRessources Word2vec : https://radimrehurek.com/gensim/models/word2vec.html#gensim.models.word2vec.Word2Vec Fasttext : https://fasttext.cc/docs/en/support.html Corpus: https://perso.limsi.fr/neveol/TP_ISD2020.zip Les fichiers QUAERO_FrenchMed_traindev.ospl et QUAERO_FrenchPress_traindev.ospl seront utilisés pour l\u0026rsquo;apprentissage des embeddings. Ils contiennent des corpus au format «une phrase par ligne», avec une segmentation des tokens qui sont séparés par des espaces. Outils nécessaires Il est recommandé d\u0026rsquo;utiliser google colab pour travailler le TP. Avant de commencer il faut installer les outils nécessaires.\n# Installer les outils nécessaires pour la création des embeddings pip install gensim pip install fasttext Apprentissage des embeddings de mot La première étape de votre travail va être de créer des scripts python et bash permettant d\u0026rsquo;apprendre les différentes approches d’embeddings word2vec (Cbow, skipgram) et fasttext (Cbow) sur les deux corpus médical et non médical QUAERO_FrenchMed et QUAERO_FrenchPress (au total 6 embeddings).\nSuivez les étapes nécessaires dans la documentation pour créer et sauvegarder les modèles et les embeddings de mots.\nVous pouvez utiliser ces hyper-paramètres pour l\u0026rsquo;apprentissage des embeddings : dim=100, min_count=1.\nSimilarité sémantique La deuxième étape consiste à trouver les mots les plus proches d\u0026rsquo;un mot donné en s\u0026rsquo;appuyant sur le calcul de similarité cosinus. Plusieurs évaluations à faire :\nComparer des d\u0026rsquo;embeddings entrainés sur le même corpus : tester l\u0026rsquo;impact des approches (skipgram, cbow, fasttext) sur le résultats Comparer des embeddings (même approche) entrainés sur de corpus différents (médical et non médical) : tester l\u0026rsquo;impact de données (type et quantité) sur les résultats Voici la liste de mots candidats : patient, traitement, maladie, solution, jaune\nPour l\u0026rsquo;évaluation vous pouvez utiliser soit :\nla méthode spatial de la bibliothèque python scipy, dans ce cas, vous devez charger les embeddings construits, et cherchez pour un mot donné la liste des 10 mots les plus proches la méthode most_similar du gensim, dans ce cas, vous devez charger les modèles sauvegardés vous pouvez utiliser gensim pour charger les modèles word2vec et fasttext Objective The objective of this lab session is to build and compare different word embedding approaches using the gensim and fasttext libraries. These embeddings will be trained on two different corpora: a small medical corpus (QUAERO_FrenchMed) and a large non-medical corpus (QUAERO_FrenchPress). They will be evaluated on the NER: Named Entity recognition task during the second practical session.\nYou are invited to use the word2vec (Cbow, skipgram) and fasttext (Cbow) approaches.\nRessources Word2vec : https://radimrehurek.com/gensim/models/word2vec.html#gensim.models.word2vec.Word2Vec Fasttext : https://fasttext.cc/docs/en/support.html Corpus: https://perso.limsi.fr/neveol/TP_ISD2020.zip The files QUAERO_FrenchMed_traindev.ospl et QUAERO_FrenchPress_traindev.ospl will be used for learning embeddings. They contain corpora in “one sentence per line” format, with a segmentation of the tokens which are separated by spaces. Requirements It is recommended to use Google Colab to work on the TP. Before starting, you must install the necessary tools.\n# Install the required tools to train word embeddings pip install gensim pip install fasttext Word embeddings training The first step of your work is to create python and bash scripts allowing you to train the different embeddings approaches: word2vec (Cbow, skipgram) and fasttext (Cbow), on the two medical and non-medical corpora, resulting to 6 embeddings models.\nFollow the steps in the documentation to create and save the models and the word embeddings.\nYou can use these hyper-parameters to train the embeddings: dim = 100, min_count = 1.\nSemantic similarity The second step is to find the closest words to a given word based on the cosine similarity calculation. Several evaluations to do:\nCompare embeddings trained on the same corpus: to test the impact of the embeddings approaches (skipgram, cbow, fasttext) on the results Compare embeddings (same approach) trained on different corpora (medical and non-medical): to test the impact of data (type and quantity) on the results Here is the candidate word list: patient, treatment, disease, solution, yellow\nFor the evaluation you can use either:\nspatial method of the python scipy library, in this case, you must load the embeddings vectors, and search for a given word for the list of the 10 closest words gensim\u0026rsquo;s most_similar method, in this case you have to load the saved models you can use gensim to load word2vec and fasttext models ","date":1525474800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1599609600,"objectID":"2c01261d506ea68504f64483d00a395f","permalink":"https://saharghannay.github.io/courses/cours1/example1/","publishdate":"2018-05-05T00:00:00+01:00","relpermalink":"/courses/cours1/example1/","section":"courses","summary":"[English version below]\nObjectif L\u0026rsquo;objectif du TP est de construire et de comparer différents type de plongements lexicaux (embeddings de mots) en utilisant les bibliothèques gensim et fasttext.\nCes embeddings seront entrainés sur deux corpus différents : corpus en domaine médical (QUAERO_FrenchMed) de petite taille et un corpus non médical (QUAERO_FrenchPress) de grande taille. Ils seront évalués sur la tâche de détection d’entités nommées (NER : Named Entity recognition) pendant le TP2 (l’après midi).","tags":null,"title":"Word embeddings training","type":"docs"},{"authors":null,"categories":null,"content":"[English version below]\nObjectif L\u0026rsquo;objectif du TP est d\u0026rsquo;évaluer la performance des embeddings appris dans le TP1 ainsi qu\u0026rsquo;un modèle Transformer (BERT) sur la tâche d\u0026rsquo;entités nommées (NER) dans le domaine médicale. Un modèle NER par type d\u0026rsquo;embeddings sera appris et évalué.\nRessources Les scripts à adapter pour la tâche de classification de séquence, un pour exécuter les modèles LSTM et CNN, un autre pour exécuter les modèles Transformer (BERT) Corpus: https://perso.limsi.fr/neveol/TP_ISD2020.zip Outils nécessaires Veuillez installer les dépendances nécessaires pour executer les scripts\nPrésentation rapide des corpus : Nous utiliserons un corpus annoté en entités issu du domaine médical (QUAERO_FrenchMed) de petit taille.\nCe corpus vous est fourni dans un format similaire au format conll : il contient cinq colonnes séparées par des espaces.\nChaque mot correspond à une ligne et les phrases sont séparées par une ligne vide. Les colonnes correspondent dans l\u0026rsquo;ordre à l\u0026rsquo;index du mot dans la phrase, le mot, deux autres colonnes qui ne seront pas utilisées et la dernière colonne représente l\u0026rsquo;étiquette d\u0026rsquo;entité nommée.\nLes étiquettes d’entité nommée sont au format I-TYPE qui indique que le mot fait partie d’une entité de type TYPE. Si deux entités de même type se suivent, le premier mot de la seconde aura pour étiquette B-TYPE pour indiquer qu’il s\u0026rsquo;agit d’une nouvelle entité. L’étiquette O indique que le mot ne fait pas partie d’une entité.\nCréation de modèles Afin de réaliser le travail il faut adapter les scripts pour la tâche de NER (étiquetage de séquence): principalement le chargement des données, la fonction objective (si besoin)\nEn plus de cela, dans le script cnn_classification.py, les embeddings sont initialisés aléatoirement, il faut faire les modifications nécessaires pour les initialisés avec les embeddings appris dans le TP1. Dans le script transformer_classification il faut changer \u0026lsquo;AutoModelForSequenceClassification\u0026rsquo; par \u0026lsquo;AutoModelForTokenClassification\u0026rsquo; Les résultats seront évaluer en termes de rappel, précision et F1 Questions Quel modèle obtient les meilleures performances ? Voyez vous des différences entre les embeddings appris sur deux corpus différents de TP1 ? Comparer ces résultats avec un modèle Transformer. Objective The objective of the lab session is to evaluate the performance of the embeddings learned in TP1 as well as a Transformer model (BERT) on the named entity task (NER) in the medical domain. A NER model for each embeddings type will be learned and evaluated.\nRessources The scripts to be adapted for the sequence classification task, one to run the LSTM and CNN models, another to run the Transformer (BERT) models Corpus: https://perso.limsi.fr/neveol/TP_ISD2020.zip Requirements Please install the dependencies to run the scripts\nQuick overview of the datasets : We will use a small medical corpus (QUAERO_FrenchMed) with named entity annotations.\nThe dataset is provided in conll-like format and contain five columns separated by white spaces. Each word (or token) corresponds to a line and sentences are separated by an empty line.\nThe columns correspond to: the token index within the sentence, the token, two columns that will not be used in this lab and finally, the last column contains the named entity tag.\nNamed entity tags are in the I-TYPE format, which indicates that the word is part of a TYPE entity. If two entities follow each other, the first word of the second entity will get a B-TYPE tag to indicate that it is a new entity. The O tag indicates that the word is not part of an entity.\nNER models training In order to do the work, it is necessary to adapt the scripts for the NER task (token classification): mainly the data loading, the objective function (if needed)\nIn addition to that, in the cnn_classification.py script, the embeddings are initialized randomly, it is necessary to make the modifications to initialize them with the embeddings learned in TP1. In the transformer_classification script, it is necessary to change \u0026lsquo;AutoModelForSequenceClassification\u0026rsquo; to \u0026lsquo;AutoModelForTokenClassification\u0026rsquo; The results will be evaluated in terms of recall, precision and F1 Questions Which model provides the best performance on each dataset? Do you see any differences between the embeddings learned on two different corpora of TP1? Compare these results with a Transformer model. ","date":1557010800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1557010800,"objectID":"f95e094aed92b488d1c8ae122805ac1d","permalink":"https://saharghannay.github.io/courses/cours1/example2/","publishdate":"2019-05-05T00:00:00+01:00","relpermalink":"/courses/cours1/example2/","section":"courses","summary":"[English version below]\nObjectif L\u0026rsquo;objectif du TP est d\u0026rsquo;évaluer la performance des embeddings appris dans le TP1 ainsi qu\u0026rsquo;un modèle Transformer (BERT) sur la tâche d\u0026rsquo;entités nommées (NER) dans le domaine médicale. Un modèle NER par type d\u0026rsquo;embeddings sera appris et évalué.\nRessources Les scripts à adapter pour la tâche de classification de séquence, un pour exécuter les modèles LSTM et CNN, un autre pour exécuter les modèles Transformer (BERT) Corpus: https://perso.","tags":null,"title":"Named entity recognition","type":"docs"},{"authors":["**Laperrière G.**","Nguyen H.","Ghannay S.","Jabaian B.","Estève Y."],"categories":null,"content":"","date":1688342400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1688342400,"objectID":"091f82e12776d16c914911e521df9d04","permalink":"https://saharghannay.github.io/publication/conference-paper/arxiv23/","publishdate":"2023-07-03T00:00:00Z","relpermalink":"/publication/conference-paper/arxiv23/","section":"publication","summary":"Over the past few years, self-supervised learned speech representations have emerged as fruitful replacements for conventional surface representations when solving Spoken Language Understanding (SLU) tasks. Simultaneously, multilingual models trained on massive textual data were introduced to encode language agnostic semantics. Recently, the SAMU-XLSR approach introduced a way to make profit from such textual models to enrich multilingual speech representations with language agnostic semantics. By aiming for better semantic extraction on a challenging Spoken Language Understanding task and in consideration with computation costs, this study investigates a specific in-domain semantic enrichment of the SAMU-XLSR model by specializing it on a small amount of transcribed data from the downstream task. In addition, we show the benefits of the use of same-domain French and Italian benchmarks for low-resource language portability and explore cross-domain capacities of the enriched SAMU-XLSR.","tags":null,"title":"Semantic enrichment towards efficient speech representations","type":"publication"},{"authors":["**Adjali Omar**","Grimal Paul","Ferret Olivier","Ghannay Sahar","Le Borgne Hervé"],"categories":null,"content":"","date":1686528000,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1686528000,"objectID":"c6a9a8848b559e7a1edf17f03af23ab9","permalink":"https://saharghannay.github.io/publication/conference-paper/acm23/","publishdate":"2023-06-12T00:00:00Z","relpermalink":"/publication/conference-paper/acm23/","section":"publication","summary":"Recent years have shown unprecedented growth of interest in Vision-Language related tasks, with the need to address the inherent challenges of integrating linguistic and visual information to solve real-world applications. Such a typical task is Visual Question Answering (VQA), which aims to answer questions about visual content. The limitations of the VQA task in terms of question redundancy and poor linguistic variability encouraged researchers to propose Knowledge-aware Visual Question Answering tasks as a natural extension of VQA. In this paper, we tackle the KVQAE (Knowledge-based Visual Question Answering about named Entities) task, which proposes to answer questions about named entities defined in a knowledge base and grounded in visual content. In particular, besides the textual and visual information, we propose to leverage the structural information extracted from syntactic dependency trees and external knowledge graphs to help answer questions about a large spectrum of entities of various types. Thus, by combining contextual and graph-based representations using Graph Convolutional Networks (GCNs), we are able to learn meaningful embeddings for Information Retrieval tasks. Experiments on the ViQuAE public dataset show how our approach improves the state-of-the-art baselines while demonstrating the interest of injecting external knowledge to enhance multimodal information retrieval.","tags":null,"title":"Explicit Knowledge Integration for Knowledge-Aware Visual Question Answering about Named Entities","type":"publication"},{"authors":["**Laperrière G.**","Nguyen H.","Ghannay S.","Jabaian B.","Estève Y."],"categories":null,"content":"","date":1685836800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1685836800,"objectID":"8c13c78c3831a66ae4defd365f7d7ff7","permalink":"https://saharghannay.github.io/publication/conference-paper/icassp23/","publishdate":"2023-06-04T00:00:00Z","relpermalink":"/publication/conference-paper/icassp23/","section":"publication","summary":"SSL is now commonly used to capture multilingual speech representation, by exploiting huge audio speech data in several languages. In parallel, some text-based large neural models trained on huge multilingual textual documents have been introduced in order to capture the general semantics of a sentence, independently of the language, and to represent it under the form of a sentence embedding. Very recently, an approach has been introduced that takes benefit of such sentence embedding in order to continue the training of an SSL speech model in order to inject some multilingual semantic information. In a previous work, we made a layer-wise analysis in order to better understand how this semantic information is integrated into a wav2vec2.0 model. In this new study, we show how this semantic information can be specialized to a targeted downstream task dedicated to a task-oriented spoken language understanding by exploiting a small amount of transcribed data. We also show that the use of in-domain data from a close language can also be very beneficial in order to make the semantic representation captured by this enriched SSL model more accurate.","tags":null,"title":"Specialized Semantic Enrichment of Speech Representations","type":"publication"},{"authors":["**Juan Manuel Coria**","Herv{'e} Bredin","Sahar Ghannay","Sophie Rosset"],"categories":null,"content":"","date":1673222400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1673222400,"objectID":"ca1da0ba59696bdd51deea82be83efbe","permalink":"https://saharghannay.github.io/publication/conference-paper/slt2023/","publishdate":"2023-01-09T00:00:00Z","relpermalink":"/publication/conference-paper/slt2023/","section":"publication","summary":"In conventional domain adaptation for speaker diarization, a large collection of annotated conversations from the target domain is required. In this work, we propose a novel continual training scheme for domain adaptation of an end-to-end speaker diarization system, which processes one conversation at a time and benefits from full self-supervision thanks to pseudo-labels. The qualities of our method allow for autonomous adaptation (e.g. of a voice assistant to a new household), while also avoiding permanent storage of possibly sensitive user conversations. We experiment extensively on the 11 domains of the DIHARD III corpus and show the effectiveness of our approach with respect to a pre-trained baseline, achieving a relative 17% performance improvement. We also find that data augmentation and a well-defined target domain are key factors to avoid divergence and to benefit from transfer.","tags":null,"title":"Continual self-supervised domain adaptation for end-to-end speaker diarization","type":"publication"},{"authors":["**OralieCattan**","Sahar Ghannay","Christophe Servan","Sophie Rosset"],"categories":null,"content":"","date":1663459200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1663459200,"objectID":"769aba1e46fca6f1fc124bf7297cd896","permalink":"https://saharghannay.github.io/publication/conference-paper/is2022/","publishdate":"2022-09-18T00:00:00Z","relpermalink":"/publication/conference-paper/is2022/","section":"publication","summary":"In the last five years, the rise of the self-attentional Transformerbased architectures led to state-of-the-art performances over many natural language tasks. Although these approaches are increasingly popular, they require large amounts of data and computational resources. There is still a substantial need for benchmarking methodologies ever upwards on under-resourced languages in data-scarce application conditions. Most pre-trained language models were massively studied using the English language and only a few of them were evaluated on French. In this paper, we propose a unified benchmark, focused on evaluating models quality and their ecological impact on two well-known French spoken language understanding tasks. Especially we benchmark thirteen well-established Transformer-based models on the two available spoken language understanding tasks for French: MEDIA and ATIS-FR. Within this framework, we show that compact models can reach comparable results to bigger ones while their ecological impact is considerably lower. However, this assumption is nuanced and depends on the considered compression method.","tags":null,"title":"Benchmarking Transformers-based models on French Spoken Language Understanding tasks","type":"publication"},{"authors":["**Mdhaffar Salima**","Pelloin Valentin","Caubrière Antoine","Laperrière Gaëlle","Ghannay Sahar","Jabaian Bassam","Camelin Nathalin","Estève Yannick"],"categories":null,"content":"","date":1655683200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1655683200,"objectID":"ac5cb8bc7531f7d11b7201b99e02c714","permalink":"https://saharghannay.github.io/publication/conference-paper/lrec22_2/","publishdate":"2022-06-20T00:00:00Z","relpermalink":"/publication/conference-paper/lrec22_2/","section":"publication","summary":"Pretrained models through self-supervised learning have been recently introduced for both acoustic and language modeling. Applied to spoken language understanding tasks, these models have shown their great potential by improving the state-of-the-art performances on challenging benchmark datasets. In this paper, we present an error analysis reached by the use of such models on the French MEDIA benchmark dataset, known as being one of the most challenging benchmarks for the slot filling task among all the benchmarks accessible to the entire research community. One year ago, the state-of-art system reached a Concept Error Rate (CER) of 13.6{\\%} through the use of a end-to-end neural architecture. Some months later, a cascade approach based on the sequential use of a fine-tuned wav2vec2.0 model and a fine-tuned BERT model reaches a CER of 11.2{\\%}. This significant improvement raises questions about the type of errors that remain difficult to treat, but also about those that have been corrected using these models pre-trained through self-supervision learning on a large amount of data. This study brings some answers in order to better understand the limits of such models and open new perspectives to continue improving the performance.\"","tags":null,"title":"Impact Analysis of the Use of Speech and Language Models Pretrained by Self-Supersivion for Spoken Language Understanding","type":"publication"},{"authors":["**Laperrière Gaëlle**","Pelloin Valentin","Caubrière Antoine","Mdhaffar Salima","Camelin Nathalin","Ghannay Sahar","Jabaian Bassam","Estève Yannick"],"categories":null,"content":"","date":1655683200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1655683200,"objectID":"2aed99e5f74c751efcdc3486a85bd884","permalink":"https://saharghannay.github.io/publication/conference-paper/lrec22_1/","publishdate":"2022-06-20T00:00:00Z","relpermalink":"/publication/conference-paper/lrec22_1/","section":"publication","summary":"With the emergence of neural end-to-end approaches for spoken language understanding (SLU), a growing number of studies have been presented during these last three years on this topic. The major part of these works addresses the spoken language understanding domain through a simple task like speech intent detection. In this context, new benchmark datasets have also been produced and shared with the community related to this task. In this paper, we focus on the French MEDIA SLU dataset, distributed since 2005 and used as a benchmark dataset for a large number of research works. This dataset has been shown as being the most challenging one among those accessible to the research community. Distributed by ELRA, this corpus is free for academic research since 2019. Unfortunately, the MEDIA dataset is not really used beyond the French research community. To facilitate its use, a complete recipe, including data preparation, training and evaluation scripts, has been built and integrated to SpeechBrain, an already popular open-source and all-in-one conversational AI toolkit based on PyTorch. This recipe is presented in this paper. In addition, based on the feedback of some researchers who have worked on this dataset for several years, some corrections have been brought to the initial manual annotation: the new version of the data will also be integrated into the ELRA catalogue, as the original one. More, a significant amount of data collected during the construction of the MEDIA corpus in the 2000s was never used until now: we present the first results reached on this subset {---} also included in the MEDIA SpeechBrain recipe {---} , that will be used for now as the MEDIA test2. Last, we discuss evaluation issues.","tags":null,"title":"The Spoken Language Understanding {MEDIA} Benchmark Dataset in the Era of Deep Learning: data updates, training and evaluation tools","type":"publication"},{"authors":["**OralieCattan**","Sahar Ghannay","Christophe Servan","Sophie Rosset"],"categories":null,"content":"","date":1655078400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1655078400,"objectID":"ad04450e080bf92ea258a5809b249a1f","permalink":"https://saharghannay.github.io/publication/conference-paper/jep_2022_1/","publishdate":"2022-06-13T00:00:00Z","relpermalink":"/publication/conference-paper/jep_2022_1/","section":"publication","summary":"Au cours des cinq dernières années, les approches par transfert utilisant les modèles de type Transformers ont établit l'État de l'Art sur de nombreuses tâches du Traitement Automatique des Langues. Ces approches deviennent de plus en plus populaires et nécessitent une grande quantité de données et de ressources computationnelles. La plupart des modèles de langue pré-entraînés ont fait l'objet de nombreuses études en anglais et seulement quelques-uns d'entre eux ont été évalués sur une tâche de compréhension de la parole en français. Dans cet article, nous proposons un tour d'horizon de référence, axé sur l'évaluation de la qualité de treize modèles bien établis basés sur les modèles Transformers. Les deux tâches de compréhension de la parole considérées sont MEDIA et ATIS-FR.","tags":null,"title":"Étude comparative de modèles Transformers en compréhension de la parole en français","type":"publication"},{"authors":["**Laperrière Gaëlle**","Pelloin Valentin","Caubrière Antoine","Mdhaffar Salima","Camelin Nathalin","Ghannay Sahar","Jabaian Bassam","Estève Yannick"],"categories":null,"content":"","date":1655078400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1655078400,"objectID":"958bcb067692efc16b15d1ea865d969a","permalink":"https://saharghannay.github.io/publication/conference-paper/jep_2022_2/","publishdate":"2022-06-13T00:00:00Z","relpermalink":"/publication/conference-paper/jep_2022_2/","section":"publication","summary":"Nous discutons ici du jeu de données françaises de référence MEDIA, créé en 2005 et distribué par ELRA gratuitement pour la recherche académique depuis 2020. Bien que parmi les plus riches et complexes à traiter, ces données sont rarement utilisées au-delà de la communauté scientifique française. Pour en faciliter l'usage dans un contexte d'apprentissage profond, une recette complète a été intégrée à SpeechBrain, une boite à outils logicielle dédiée au traitement de la parole par des approches neuronales, de plus en plus populaire au niveau international. De plus, des corrections ont été apportées aux annotations manuelles, proposées par différents chercheurs ayant régulièrement travaillé sur ces données. Cette nouvelle version du corpus sera intégrée au catalogue de ELRA. Un nouvel ensemble de données jamais utilisées jusqu'à présent, mais collectées durant la création du corpus original, est également décrit. Enfin, nous abordons des considérations liées à l'évaluation de la tâche MEDIA.","tags":null,"title":"Le benchmark MEDIA revisité : données, outils et évaluation dans un contexte d'apprentissage profond","type":"publication"},{"authors":["**Juan Manuel Coria**","Hervé Bredin","Sahar Ghannay","Sophie Rosset"],"categories":null,"content":"","date":1639699200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1639699200,"objectID":"960cc3413412ec5b772d9640d72b4176","permalink":"https://saharghannay.github.io/publication/conference-paper/asru-juan-2021/","publishdate":"2021-12-17T00:00:00Z","relpermalink":"/publication/conference-paper/asru-juan-2021/","section":"publication","summary":"We propose to address online speaker diarization as a combination of incremental clustering and local diarization applied to a rolling buffer updated every 500ms. Every single step of the proposed pipeline is designed to take full advantage of the strong ability of a recently proposed end-to-end overlap-aware segmentation to detect and separate overlapping speakers. In particular, we propose a modified version of the statistics pooling layer (initially introduced in the x-vector architecture) to give less weight to frames where the segmentation model predicts simultaneous speakers. Furthermore, we derive cannot-link constraints from the initial segmentation step to prevent two local speakers from being wrongfully merged during the incremental clustering step. Finally, we show how the latency of the proposed approach can be adjusted between 500ms and 5s to match the requirements of a particular use case, and we provide a systematic analysis of the influence of latency on the overall performance (on AMI, DIHARD and VoxConverse).","tags":null,"title":"OVERLAP-AWARE LOW-LATENCY ONLINE SPEAKER DIARIZATION BASED ON END-TO-END LOCAL SEGMENTATION","type":"publication"},{"authors":["**Nesrine Bannour**","Sahar Ghannay","Aurélie Névéol","Anne-Laure Ligozat"],"categories":null,"content":"","date":1636502400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1636502400,"objectID":"ecf10d765a37df3b70f8435e9485449a","permalink":"https://saharghannay.github.io/publication/conference-paper/sustainlp_2021/","publishdate":"2021-11-10T00:00:00Z","relpermalink":"/publication/conference-paper/sustainlp_2021/","section":"publication","summary":"Modern Natural Language Processing (NLP) makes intensive use of deep learning methods because of the accuracy they offer for a variety of applications. Due to the significant environmental impact of deep learning, cost-benefit analysis including carbon footprint as well as accuracy measures has been suggested to better document the use of NLP methods for research or deployment. In this paper, we review the tools that are available to measure energy use and CO2 emissions of NLP methods. We describe the scope of the measures provided and compare the use of six tools (carbon tracker, experiment impact tracker, green algorithms, ML CO2 impact, energy usage and cumulator) on named entity recognition experiments performed on different computational set-ups (local server vs. computing facility). Based on these findings, we propose actionable recommendations to accurately measure the environmental impact of NLP experiments.","tags":null,"title":"Evaluating the carbon footprint of NLP methods: a survey and analysis of existing tools","type":"publication"},{"authors":["**Sahar Ghannay**","Antoine Caubrière","Salima Mdhaffar","Gaëlle Laperrière","Bassam Jabaian","Yannick Estève"],"categories":null,"content":"","date":1632268800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1632268800,"objectID":"891a284f3b2e2964b61ca1284fd9f7cd","permalink":"https://saharghannay.github.io/publication/conference-paper/specom-2021-sg/","publishdate":"2021-09-22T00:00:00Z","relpermalink":"/publication/conference-paper/specom-2021-sg/","section":"publication","summary":"Spoken language understanding (SLU) topic has seen a lot of progress these last three years, with the emergence of end-to-end neural approaches. Spoken language understanding refers to natural language processing tasks related to semantic extraction from speech signal, like named entity recognition from speech or slot filling task in a context of human-machine dialogue. Classically, SLU tasks were processed through a cascade approach that consists in applying, firstly, an automatic speech recognition process, followed by a natural language processing module applied to the automatic transcriptions. These three last years, end-to-end neural approaches, based on deep neural networks, have been proposed in order to directly extract the semantics from speech signal, by using a single neural model. More recent works on self-supervised training with unlabeled data open new perspectives in term of performance for automatic speech recognition and natural language processing. In this paper, we present a brief overview of the recent advances on the French MEDIA benchmark dataset for SLU, with or without the use of additional data. We also present our last results that significantly outperform the current state-of-the-art with a Concept Error Rate (CER) of 11.2%, instead of 13.6% for the last state-of-the-art system presented this year.","tags":null,"title":"Where Are We in Semantic Concept Extraction for Spoken Language Understanding?","type":"publication"},{"authors":["**Sahar Ghannay**","Christophe Servan","Sophie Rosset"],"categories":null,"content":"","date":1607385600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1607385600,"objectID":"85ebd795de14df54fac2ab6127c8cb23","permalink":"https://saharghannay.github.io/publication/conference-paper/ghannay-2020-coling/","publishdate":"2020-12-08T00:00:00Z","relpermalink":"/publication/conference-paper/ghannay-2020-coling/","section":"publication","summary":"In this paper, we present a study on a French Spoken Language Understanding (SLU) task: the MEDIA task. Many works and studies have been proposed for many tasks, but most of them are focused on English language and tasks. The exploration of a richer language like French within the framework of a SLU task implies to recent approaches to handle this difficulty. Since the MEDIA task seems to be one of the most difficult, according several previous studies, we propose to explore Neural Networks approaches focusing of three aspects: firstly, the Neural Network inputs and more specifically the word embeddings; secondly, we compared French version of BERT against the best setup through different ways; Finally, the comparison against State-of-the-Art approaches. Results show that the word embeddings trained on a small corpus need to be updated during SLU model training. Furthermore, the French BERT fine-tuned approaches outperform the classical Neural Network Architectures and achieves state of the art results. However, the contextual embeddings extracted from one of the French BERT approaches achieve comparable results in comparison to word embedding, when integrated into the proposed neural architecture.","tags":null,"title":"Neural Networks approaches focused on French Spoken Language Understanding: application to the MEDIA Evaluation Task","type":"publication"},{"authors":["**Coria Juan Manuel**","Veron Mathilde","Ghannay Sahar","Bernard Guillaume","Bredin Hervé","Galibert Olivier","Rosset Sophie"],"categories":null,"content":"","date":1601510400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1601510400,"objectID":"7f9989c6ec355c66a1a5ba11d68dbfa6","permalink":"https://saharghannay.github.io/publication/conference-paper/wp2022/","publishdate":"2020-10-01T00:00:00Z","relpermalink":"/publication/conference-paper/wp2022/","section":"publication","summary":"Knowledge transfer between neural language models is a widely used technique that has proven to improve performance in a multitude of natural language tasks, in particular with the recent rise of large pre-trained language models like BERT. Similarly, high crosslingual transfer has been shown to occur in multilingual language models. Hence, it is of great importance to better understand this phenomenon as well as its limits. While most studies about cross-lingual transfer focus on training on independent and identically distributed (i.e. i.i.d.) samples, in this paper we study cross-lingual transfer in a continual learning setting on two sequence labeling tasks: slotfilling and named entity recognition. We investigate this by training multilingual BERT on sequences of 9 languages, one language at a time, on the MultiATIS++ and MultiCoNER corpora. Our first findings are that forward transfer between languages is retained although forgetting is present. Additional experiments show that lost performance can be recovered with as little as a single training epoch even if forgetting was high, which can be explained by a progressive shift of model parameters towards a better multilingual initialization. We also find that commonly used metrics might be insufficient to assess continual learning performance.","tags":null,"title":"Analyzing BERT Cross-lingual Transfer Capabilities in Continual Sequence Labeling","type":"publication"},{"authors":["**Antoine Caubrière**","Sahar Ghannay","Nathalia Tomashenko","Renato De Mori","Emmanuel Morin","Yannick Estève"],"categories":null,"content":"","date":1588550400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1588550400,"objectID":"3e0101641539de073ce1b2ff0e190890","permalink":"https://saharghannay.github.io/publication/conference-paper/caubriere-2020-sluanaly/","publishdate":"2020-05-04T00:00:00Z","relpermalink":"/publication/conference-paper/caubriere-2020-sluanaly/","section":"publication","summary":"This paper presents a qualitative study of errors produced by an end-to-end spoken language understanding (SLU) system (speech signal to concepts) that reaches state of the art performance. Different studies are proposed to better understand the weaknesses of such systems: comparison to a classical pipeline SLU system, a study on the cause of concept deletions (the most frequent error), observation of a problem in the capability of the end-to-end SLU system to segment correctly concepts, analysis of the system behavior to process unseen concept/value pairs, analysis of the benefit of the curriculum-based transfer learning approach. Last, we proposed a way to compute embeddings of sub-sequences that seem to contain relevant information for future work.","tags":null,"title":"Error Analysis Applied to End-to-End Spoken Language Understanding","type":"publication"},{"authors":["**Sahar Ghannay**","Antoine Neuraz","Sophie Rosset"],"categories":null,"content":"","date":1588550400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1588550400,"objectID":"58a28f6eba3a0d1f4f3c61c9124d28c5","permalink":"https://saharghannay.github.io/publication/conference-paper/ghannay-2020-sluembed/","publishdate":"2020-05-04T00:00:00Z","relpermalink":"/publication/conference-paper/ghannay-2020-sluembed/","section":"publication","summary":"Word embeddings are shown to be a great asset for several Natural Language and Speech Processing tasks. While they are already evaluated on various NLP tasks, their evaluation on spoken or natural language understanding (SLU) is less studied. The goal of this study is two-fold: firstly, it focuses on semantic evaluation of common word embeddings approaches for SLU task; secondly, it investigates the use of two different data sets to train the embeddings: small and task-dependent corpus or huge and out-of-domain corpus. Experiments are carried out on 5 benchmark corpora (ATIS, SNIPS, SNIPS70, M2M, MEDIA), on which a relevance ranking was proposed in the literature. Interestingly, the performance of the embeddings is independent of the difficulty of the corpora. Moreover, the embeddings trained on huge and out-of-domain corpus yields to better results than the ones trained on small and task-dependent corpus.","tags":null,"title":"What is best for spoken language understanding: small but task-dependant embeddings or huge but out-of-domain embeddings?","type":"publication"},{"authors":["**Juan Manuel Coria**","Herv{'e} Bredin","Sahar Ghannay","Sophie Rosset"],"categories":null,"content":"","date":1585612800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1585612800,"objectID":"9dbe7026340b7f2b84e9b80d32d98130","permalink":"https://saharghannay.github.io/publication/conference-paper/juan-2020-spk/","publishdate":"2020-03-31T00:00:00Z","relpermalink":"/publication/conference-paper/juan-2020-spk/","section":"publication","summary":"Despite the growing popularity of metric learning approaches, very little work has attempted to perform a fair comparison of these techniques for speaker verification. We try to fill this gap and compare several metric learning loss functions in a systematic manner on the VoxCeleb dataset. The first family of loss functions is derived from the cross entropy loss (usually used for supervised classification) and includes the congenerous cosine loss, the additive angular margin loss, and the center loss. The second family of loss functions focuses on the similarity between training samples and includes the contrastive loss and the triplet loss. We show that the additive angular margin loss function outperforms all other loss functions in the study, while learning more robust representations. Based on a combination of SincNet trainable features and the x-vector architecture, the network used in this paper brings us a step closer to a really-end-to-end speaker verification system, when combined with the additive angular margin loss, while still being competitive with the x-vector baseline. In the spirit of reproducible research, we also release open source Python code for reproducing our results, and share pretrained PyTorch models on torch. hub that can be used either directly or after fine-tuning.","tags":null,"title":"A Comparison of Metric Learning Loss Functions for End-To-End Speaker Verification","type":"publication"},{"authors":["**Veron Mathilde**","Penas Anselmo","Echegoyen Guillermo","Banerjee Somnath","Ghannay Sahar"," Rosset Sophie"],"categories":null,"content":"","date":1585612800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1585612800,"objectID":"97619913663f05809ef96d43763bf126","permalink":"https://saharghannay.github.io/publication/conference-paper/mathilde_nldb_2020/","publishdate":"2020-03-31T00:00:00Z","relpermalink":"/publication/conference-paper/mathilde_nldb_2020/","section":"publication","summary":"In a long term exploitation environment, a Question Answering (QA) system should maintain or even improve its performance over time, trying to overcome the lacks made evident through the interactions with users. We claim that, in order to make progress in the QA over Knowledge Bases (KBs) research field, we must deal with two problems at the same time: the translation of Natural Language (NL) questions into formal queries, and the detection of missing knowledge that impact the way a question is answered. The research on these two challenges has not been addressed jointly until now, what motivates the main goals of this work: (i) the definition of the problem and (ii) the development of a methodology to create the evaluation resources needed to address this challenge.","tags":null,"title":"A Cooking Knowledge Graph and Benchmark for Question Answering Evaluation in Lifelong Learning Scenarios","type":"publication"},{"authors":["**Juan Manuel Coria**","Sahar Ghannay","Herv{'e} Bredin","Sophie Rosset"],"categories":null,"content":"","date":1585612800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1585612800,"objectID":"4653b2dfdbc02f3f446b90c90363ff27","permalink":"https://saharghannay.github.io/publication/conference-paper/juan-2020-metric/","publishdate":"2020-03-31T00:00:00Z","relpermalink":"/publication/conference-paper/juan-2020-metric/","section":"publication","summary":"The  task  of  automatic  misogyny  identifica-tion  and  categorization  has  not  received  asmuch attention as other natural language taskshave,  even  though  it  is  crucial  for  identify-ing hate speech in social Internet interactions.In  this  work,  we  address  this  sentence  clas-sification  task  from  a  representation  learningperspective, using both a bidirectional LSTMand BERT optimized with the following met-ric  learning  loss  functions:   contrastive  loss,triplet  loss,  center  loss,  congenerous  cosineloss and additive angular margin loss.  We setnew state-of-the-art for the task with our fine-tuned BERT, whose sentence embeddings canbe  compared  with  a  simple  cosine  distance,and we release all our code as open source foreasy reproducibility. Moreover, we find that al-most every loss function performs equally wellin this setting, matching the regular cross en-tropy loss.","tags":null,"title":"A Metric Learning Approach to Misogyny Categorization","type":"publication"},{"authors":["**Sahar Ghannay**","Yannick Estève","Nathalie Camelin"],"categories":null,"content":"","date":1583539200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1583539200,"objectID":"8adba8c05eb1037f429999144c517881","permalink":"https://saharghannay.github.io/publication/journal-article/ghannay-2020-spcom/","publishdate":"2020-03-07T00:00:00Z","relpermalink":"/publication/journal-article/ghannay-2020-spcom/","section":"publication","summary":"This paper presents a study of continuous word representations applied to automatic detection of speech recognition errors. A neural network architecture is proposed, which is well suited to handle continuous word representations, like word embeddings. We explore the use of several types of word representations: simple and combined linguistic embeddings, and acoustic ones associated to prosodic features, extracted from the audio signal. To compensate certain phenomena highlighted by the analysis of the error average span, we propose to model the errors at the sentence level through the use of sentence embeddings. An approach to build continuous sentence representations dedicated to ASR error detection is also proposed and compared to the Doc2vec approach. Experiments are performed on automatic transcriptions generated by the LIUM ASR system applied to the French ETAPE corpus. They show that the combination of linguistic embeddings, acoustic embeddings, prosodic features, and sentence embeddings in addition to more classical features yields very competitive results. Particularly, these results show the complementarity of acoustic embeddings and prosodic information, and show that the proposed sentence embeddings dedicated to ASR error detection achieve better results than generic sentence embeddings.","tags":null,"title":"A study of continuous space word and sentence representations applied to ASR error detection","type":"publication"},{"authors":["Mathilde Veron","**Ghannay Sahar**","Anne-Laure Ligozat","Sophie Rosset"],"categories":null,"content":"","date":1556064000,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1556064000,"objectID":"cc3a3d23840550d444170792baf1d14e","permalink":"https://saharghannay.github.io/publication/conference-paper/veron-2019-ll/","publishdate":"2019-04-24T00:00:00Z","relpermalink":"/publication/conference-paper/veron-2019-ll/","section":"publication","summary":"The main objective of this paper is to propose a functional definition of lifelong learning systems adapted to the framework of task-oriented dialogue sys- tems. We mainly identified two aspects where a lifelong learning technology could be applied in such systems: to improve the natural language understanding mod- ule and to enrich the database used by the system. Given our definition, we present an example of how it could be implemented in an existing task-oriented dialogue system that is developed in the LIHLITH project.","tags":null,"title":"Lifelong learning and task-oriented dialogue system: what does it mean?","type":"publication"},{"authors":[],"categories":[],"content":"Create slides in Markdown with Academic Academic | Documentation\nFeatures Efficiently write slides in Markdown 3-in-1: Create, Present, and Publish your slides Supports speaker notes Mobile friendly slides Controls Next: Right Arrow or Space Previous: Left Arrow Start: Home Finish: End Overview: Esc Speaker notes: S Fullscreen: F Zoom: Alt + Click PDF Export: E Code Highlighting Inline code: variable\nCode block:\nporridge = \u0026quot;blueberry\u0026quot; if porridge == \u0026quot;blueberry\u0026quot;: print(\u0026quot;Eating...\u0026quot;) Math In-line math: $x + y = z$\nBlock math:\n$$ f\\left( x \\right) = ;\\frac{{2\\left( {x + 4} \\right)\\left( {x - 4} \\right)}}{{\\left( {x + 4} \\right)\\left( {x + 1} \\right)}} $$\nFragments Make content appear incrementally\n{{% fragment %}} One {{% /fragment %}} {{% fragment %}} **Two** {{% /fragment %}} {{% fragment %}} Three {{% /fragment %}} Press Space to play!\nOne **Two** Three A fragment can accept two optional parameters:\nclass: use a custom style (requires definition in custom CSS) weight: sets the order in which a fragment appears Speaker Notes Add speaker notes to your presentation\n{{% speaker_note %}} - Only the speaker can read these notes - Press `S` key to view {{% /speaker_note %}} Press the S key to view the speaker notes!\nOnly the speaker can read these notes Press S key to view Themes black: Black background, white text, blue links (default) white: White background, black text, blue links league: Gray background, white text, blue links beige: Beige background, dark text, brown links sky: Blue background, thin dark text, blue links night: Black background, thick white text, orange links serif: Cappuccino background, gray text, brown links simple: White background, black text, blue links solarized: Cream-colored background, dark green text, blue links Custom Slide Customize the slide style and background\n{{\u0026lt; slide background-image=\u0026quot;/img/boards.jpg\u0026quot; \u0026gt;}} {{\u0026lt; slide background-color=\u0026quot;#0000FF\u0026quot; \u0026gt;}} {{\u0026lt; slide class=\u0026quot;my-style\u0026quot; \u0026gt;}} Custom CSS Example Let\u0026rsquo;s make headers navy colored.\nCreate assets/css/reveal_custom.css with:\n.reveal section h1, .reveal section h2, .reveal section h3 { color: navy; } Questions? Ask\nDocumentation\n","date":1549324800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1549324800,"objectID":"0e6de1a61aa83269ff13324f3167c1a9","permalink":"https://saharghannay.github.io/slides/example/","publishdate":"2019-02-05T00:00:00Z","relpermalink":"/slides/example/","section":"slides","summary":"An introduction to using Academic's Slides feature.","tags":[],"title":"Slides","type":"slides"},{"authors":["**Sahar Ghannay**","Antoine Caubrière","Yannick Estève","Nathalie Camelin","Edwin Simonnet","Antoine Laurent","Emmanuel Morin"],"categories":null,"content":"","date":1545091200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1545091200,"objectID":"daa858cf7c29c87471fa576fe359f4ef","permalink":"https://saharghannay.github.io/publication/conference-paper/ghannay-2018-endtoend/","publishdate":"2018-12-18T00:00:00Z","relpermalink":"/publication/conference-paper/ghannay-2018-endtoend/","section":"publication","summary":"Named entity recognition (NER) is among SLU tasks that usually extract semantic information from textual documents. Until now, NER from speech is made through a pipeline process that consists in processing first an automatic speech recognition (ASR) on the audio and then processing a NER on the ASR outputs. Such approach has some disadvantages (error propagation, metric to tune ASR systems sub-optimal in regards to the final task, reduced space search at the ASR output level,...) and it is known that more integrated ap- proaches outperform sequential ones, when they can be ap- plied. In this paper, we explore an end-to-end approach that directly extracts named entities from speech, though a unique neural architecture. On a such way, a joint optimization is possible for both ASR and NER. Experiments are carried on French data easily accessible, composed of data distributed in several evaluation campaigns. The results are promising since this end-to-end approach provides similar results (F- measure=0.66 on test data) than a classical pipeline approach to detect named entity categories (F-measure=0.64). Last, we also explore this approach applied to semantic concept extrac- tion, through a slot filling task known as a spoken language understanding problem.","tags":null,"title":"End-to-end named entity and semantic concept extraction from speech","type":"publication"},{"authors":null,"categories":null,"content":"Master 2 course, Université Paris-Saclay, IUT Orsay, Computer Science Department\n2018-2020 MSc level (M2) Introduction to distributed representations, recent approaches, evaluation approaches Practical session ","date":1538697600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1538697600,"objectID":"9d1a8705dadf2f02d80c6c86762f906c","permalink":"https://saharghannay.github.io/teachings/semantic-representations/","publishdate":"2018-10-05T00:00:00Z","relpermalink":"/teachings/semantic-representations/","section":"teachings","summary":"course for MSc level (M2) about semantic representations at the Université Paris-Saclay, IUT Orsay, Computer Science Department","tags":null,"title":"Semantic Representations","type":"teachings"},{"authors":["François Hernandez","Vincent Nguyen","**Sahar Ghannay**","Natalia Tomashenko","Yannick Estève"],"categories":null,"content":"","date":1537228800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1537228800,"objectID":"22dc6719c34d54a3ed83a677623c37b3","permalink":"https://saharghannay.github.io/publication/conference-paper/hernandez-2018-tedlium/","publishdate":"2018-09-18T00:00:00Z","relpermalink":"/publication/conference-paper/hernandez-2018-tedlium/","section":"publication","summary":"In this paper, we present TED-LIUM release 3 corpus3 ded- icated to speech recognition in English, which multiplies the available data to train acoustic models in comparison with TED-LIUM 2, by a factor of more than two. We present the recent development on Auto- matic Speech Recognition (ASR) systems in comparison with the two previous releases of the TED-LIUM Corpus from 2012 and 2014. We demonstrate that, passing from 207 to 452 hours of transcribed speech training data is really more useful for end-to-end ASR systems than for HMM-based state-of-the-art ones. This is the case even if the HMM- based ASR system still outperforms the end-to-end ASR system when the size of audio training data is 452 hours, with a Word Error Rate (WER) of 6.7% and 13.7%, respectively. Finally, we propose two repar- titions of the TED-LIUM release 3 corpus: the legacy repartition that is the same as that existing in release 2, and a new repartition, calibrated and designed to make experiments on speaker adaptation. Similar to the two first releases, TED-LIUM 3 corpus will be freely available for the research community.","tags":null,"title":"TED-LIUM 3: Twice as Much Data and Corpus Repartition for Experiments on Speaker Adaptation","type":"publication"},{"authors":null,"categories":null,"content":"BSc level (L2) course, Université Paris-Saclay, IUT Orsay, Computer Science Department\n2018-2020 BSc level (L2) PHP, MySQL queries, Object Oriented Programming, cookies, sessions ","date":1536105600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1536105600,"objectID":"e3bc9ae2e6862dc16b9d9107773df61c","permalink":"https://saharghannay.github.io/teachings/service-side-web-programming/","publishdate":"2018-09-05T00:00:00Z","relpermalink":"/teachings/service-side-web-programming/","section":"teachings","summary":"course for BSc level (L2) about semantic representations at the Université Paris-Saclay, IUT Orsay, Computer Science Department","tags":null,"title":"Service side web programming","type":"teachings"},{"authors":["**Sahar Ghannay**","Yannick Estève","Nathalie Camelin"],"categories":null,"content":"","date":1533168000,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1533168000,"objectID":"d7b2700c92bc2281dda2305092444a83","permalink":"https://saharghannay.github.io/publication/conference-paper/ghannay-2018-sentem/","publishdate":"2018-08-02T00:00:00Z","relpermalink":"/publication/conference-paper/ghannay-2018-sentem/","section":"publication","summary":"This paper presents a study on the modeling of automatic speech recognition errors at the sentence level. We aim in this study to compensate certain phenomena highlighted by the analysis of outputs generated by an ASR error detection system we pre- viously proposed. We investigated three different approaches, that are based respectively on the use of sentence embeddings dedicated to ASR error detection task, on a probabilistic con- textual model, and on a bidirectional long short-term memory (BLSTM) architecture. An approach to build task-specific sen- tence embeddings is proposed and compared to the Doc2vec approach. Experiments are performed on transcriptions gen- erated by the LIUM ASR system applied to the French ETAPE corpus. They show that the proposed sentence embeddings ded- icated to ASR error detection achieve better results than generic sentence embeddings, and that the integration of task-specific embeddings in our system achieves better results than the prob- abilistic contextual model and BLSTM models.","tags":null,"title":"Task Specific Sentence Embeddings for ASR Error Detection","type":"publication"},{"authors":["**Sahar Ghannay**","Yannick Estève","Nathalie Camelin"],"categories":null,"content":"","date":1528070400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1528070400,"objectID":"cbfd2c230589c81c9425bc1eabdbedec","permalink":"https://saharghannay.github.io/publication/conference-paper/ghannay-2018-sentemf/","publishdate":"2018-06-04T00:00:00Z","relpermalink":"/publication/conference-paper/ghannay-2018-sentemf/","section":"publication","summary":"This paper presents a study on the modeling of automatic speech recognition errors at the sentence level. We aim in this study to compensate certain phenomena highlighted by the analysis of the outputs generated by the ASR error detection system we previously proposed. We investigated three different approaches, that are based respectively on the use of sentence embeddings dedicated to ASR error detection task, a probabilistic contextual model (PCM) and a bidirectional long short term memory (BLSTM) architecture. An approach to build task-specific sentence embeddings is proposed and compared to the Doc2vec approach. Experiments are performed on transcriptions generated by the LIUM ASR system applied to the ETAPE corpus. They show that the proposed sentence embeddings dedicated to ASR error detection achieve better results than generic sentence embeddings, and that the integration of task-specific embeddings in our system achieves better results than the PCM and BLSTM models.","tags":null,"title":"Représentations de phrases dans un espace continu spécifiques à la tâche de détection d'erreurs","type":"publication"},{"authors":["Edwin Simonnet","**Sahar Ghannay**","Nathalie Camelin","Yannick Estève"],"categories":null,"content":"","date":1528070400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1528070400,"objectID":"665280f26d97eef03c027dbe1251a426","permalink":"https://saharghannay.github.io/publication/conference-paper/simonnet-2018-sluerrf/","publishdate":"2018-06-04T00:00:00Z","relpermalink":"/publication/conference-paper/simonnet-2018-sluerrf/","section":"publication","summary":"This paper presents an approach to simulate automatic speech recognition (ASR) errors from manual transcriptions and how it can be used to improve the performance of spoken language understanding (SLU) systems. The proposed method is based on the use of both acoustic and linguistic word embeddings in order to define a similarity measure between words. This measure is dedicated to predict ASR confusions. Actually, we assume that words acoustically and linguistically close are the ones confused by an ASR system. Experiments were carried on the French MEDIA corpus focusing on hotel reservation. They show that this approach significantly improves SLU system performance with a relative reduction of 21.2% of concept/value error rate (CVER), particularly when the SLU system is based on a neural approach (reduction of 22.4% of CVER). A comparison to a naive noising approach shows that the proposed noising approach is particularly relevant.","tags":null,"title":"Simulation d'erreurs de reconnaissance automatique dans un cadre de compréhension de la parole","type":"publication"},{"authors":["**Sahar Ghannay**","Antoine Caubrière","Yannick Estève","Antoine Laurent","Emmanuel Morin"],"categories":null,"content":"","date":1527638400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1527638400,"objectID":"f6d8b351a9d72a51bac7bca963c69845","permalink":"https://saharghannay.github.io/publication/conference-paper/ghannay-2018-endtoend2/","publishdate":"2018-05-30T00:00:00Z","relpermalink":"/publication/conference-paper/ghannay-2018-endtoend2/","section":"publication","summary":"Named entity recognition (NER) is among SLU tasks that usu- ally extract semantic information from textual documents. Un- til now, NER from speech is made through a pipeline process that consists in processing first an automatic speech recognition (ASR) on the audio and then processing a NER on the ASR outputs. Such approach has some disadvantages (error propa- gation, metric to tune ASR systems sub-optimal in regards to the final task, reduced space search at the ASR output level,...) and it is known that more integrated approaches outperform se- quential ones, when they can be applied. In this paper, we present a first study of end-to-end approach that directly ex- tracts named entities from speech, though a unique neural ar- chitecture. On a such way, a joint optimization is able for both ASR and NER. Experiments are carried on French data eas- ily accessible, composed of data distributed in several evalua- tion campaign. Experimental results show that this end-to-end approach provides better results (F-measure=0.69 on test data) than a classical pipeline approach to detect named entity cate- gories (F-measure=0.65).","tags":null,"title":"End-to-end named entity extraction from speech","type":"publication"},{"authors":["Edwin Simonnet","**Sahar Ghannay**","Nathalie Camelin","Yannick Estève"],"categories":null,"content":"","date":1525651200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1525651200,"objectID":"0e441e45a12a05528e09b9bcc94ac032","permalink":"https://saharghannay.github.io/publication/conference-paper/simonnet-2017-sluerr/","publishdate":"2018-05-07T00:00:00Z","relpermalink":"/publication/conference-paper/simonnet-2017-sluerr/","section":"publication","summary":"This paper presents an approach to simulate automatic speech recognition (ASR) errors from manual transcriptions and describes how it can be used to improve the performance of spoken language understanding (SLU) systems. In particular, we point out that this noising process is very usefull to obtain a more robust SLU system to ASR errors in case of insufficient training data or more if ASR transcriptions are not available during the training of the SLU model. The proposed method is based on the use of both acoustic and linguistic word embeddings in order to define a similarity measure between words dedicated to predict ASR confusions. Actually, we assume that words acoustically and linguistically close are the ones confused by an ASR system. By using this similarity measure in order to randomly substitute correct words by potentially confusing words in manual annotations used to train CRF- or neural based SLU systems, we augment the training corpus with these new noisy data. Experiments were carried on the French MEDIA corpus focusing on hotel reservation. They show that this approach significantly improves SLU system performance with a relative reduction of 21.2% of concept/value error rate (CVER), particularly when the SLU system is based on a neural approach (re- duction of 22.4% of CVER). A comparison to a naive noising approach shows that the proposed noising approach is particularly relevant.","tags":null,"title":"Simulating ASR errors for training SLU systems","type":"publication"},{"authors":["**Sahar Ghannay**","Yannick Estève","Nathalie Camelin"],"categories":null,"content":"","date":1508716800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1508716800,"objectID":"b8ca8391870a18c14d75a45016fd55de","permalink":"https://saharghannay.github.io/publication/conference-paper/ghannay-2017-enriching/","publishdate":"2017-10-23T00:00:00Z","relpermalink":"/publication/conference-paper/ghannay-2017-enriching/","section":"publication","summary":"The paper proposes a new approach for a posteriori enrichment of au- tomatic speech recognition (ASR) confusion networks (CNs). CNs are usually needed to decrease word error rate and to compute confidence measures, but they are also used in many ways in order to improve post-processing of ASR outputs. For instance, they can be helpfully used to propose alternative word hypotheses when ASR outputs are corrected by a human on post-edition. However, CNs bins do not have a fixed length, and sometimes contain only one or two word hypothe- ses: in this case the number of alternatives to correct a misrecognized word is very low, reducing the chance of helping the human annotator. Our approach for CN enrichment is based on a new similarity measure presented in this paper, computed from acoustic and linguistic word embeddings, that al- lows us to take into consideration both acoustic and linguistic similarities between two words. Experimental results show that our approach is relevant: enriched CNs (for a bin size equals to 6) increase the potential correction of erroneous words by 23% than initial CNs produced by an ASR system. In our experiments, a spoken language understanding task is also targeted.","tags":null,"title":"Enriching confusion networks for post-processing","type":"publication"},{"authors":["**Ghannay Sahar**"],"categories":null,"content":"","date":1506470400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1506470400,"objectID":"86617247d40207af807e8174129919b9","permalink":"https://saharghannay.github.io/publication/thesis/ghannay-2017-phd/","publishdate":"2017-09-27T00:00:00Z","relpermalink":"/publication/thesis/ghannay-2017-phd/","section":"publication","summary":"My thesis concerns a study of continuous word representations applied to the au- tomatic detection of speech recognition errors. Recent advances in the field of speech processing have led to significant improvements in speech recognition performances. However, recognition errors are still unavoidable. This reflects their sensitivity to the variability, e.g. to acoustic conditions, speaker, language style, etc. Our study focuses on the use of a neural approach to improve ASR error detection, using word embeddings. These representations have proven to be a great asset in various natural language processing tasks (NLP). The exploitation of continuous word representations is motivated by the fact that ASR error detection consists on locating the possible linguistic or acoustic in- congruities in automatic transcriptions. The aim is therefore to find the appropriate word representation which makes it possible to capture pertinent information in order to be able to detect these anomalies. Our contribution in this thesis concerns several initiatives. First, we start with a preliminary study in which we propose a neural architecture able to integrate different types of features, including word embeddings. Second, we propose a deep study of continuous word representations. This study focuses on the evaluation of different types of linguistic word embeddings and their combination in order to take advantage of their complementarities. On the other hand, it focuses on acoustic embeddings. The proposed approach relies on the use of a convolution neural network to build acoustic signal embeddings, and a deep neural network to build acoustic word embeddings. In addition, we propose two approaches to evaluate the performance of acoustic word embeddings. We also pro- pose to enrich the word representation, in input of the ASR error detection system, by prosodic features in addition to linguistic and acoustic embeddings. Integrating this information into our neural architecture provides a significant improvement in terms of classification error rate reduction in comparison to a conditional random field (CRF) based state-of-the-art approach. Then, we present a study on the analysis of classification errors, with the aim of perceiving the errors that are difficult to detect. Perspectives for improving the performance of our system are also proposed, by modelling the errors at the sen- tence level. Finally, we exploit the linguistic and acoustic embeddings as well as the information provided by our ASR error detection system in several downstream applications.","tags":null,"title":"A study of continuous word representations applied to the automatic detection of speech recognition errors","type":"publication"},{"authors":["Edwin Simonnet","**Sahar Ghannay**","Nathalie Camelin","Yannick Estève","Renato De Mori"],"categories":null,"content":"","date":1503187200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1503187200,"objectID":"5ddc8febabf47451ce0573d74c223e03","permalink":"https://saharghannay.github.io/publication/conference-paper/simonnet-2017-slu/","publishdate":"2017-08-20T00:00:00Z","relpermalink":"/publication/conference-paper/simonnet-2017-slu/","section":"publication","summary":"This paper addresses the problem of automatic speech recog- nition (ASR) error detection and their use for improving spo- ken language understanding (SLU) systems. In this study, the SLU task consists in automatically extracting, from ASR tran- scriptions, semantic concepts and concept/values pairs in a e.g touristic information system. An approach is proposed for en- riching the set of semantic labels with error specific labels and by using a recently proposed neural approach based on word embeddings to compute well calibrated ASR confidence mea- sures. Experimental results are reported showing that it is possi- ble to decrease significantly the Concept/Value Error Rate with a state of the art system, outperforming previously published re- sults performance on the same experimental data. It also shown that combining an SLU approach based on conditional random fields with a neural encoder/decoder attention based architec- ture, it is possible to effectively identifying confidence islands and uncertain semantic output segments useful for deciding appropriate error handling actions by the dialogue manager strategy.","tags":null,"title":"ASR Error Management for Improving Spoken Language Understanding","type":"publication"},{"authors":["**Sahar Ghannay**","Loïc Barrault"],"categories":null,"content":"","date":1493251200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1493251200,"objectID":"8605fba695834796cc8ab4f3cf647f6e","permalink":"https://saharghannay.github.io/publication/conference-paper/ghannay-2014-trans/","publishdate":"2017-04-27T00:00:00Z","relpermalink":"/publication/conference-paper/ghannay-2014-trans/","section":"publication","summary":"This paper describes the development op- erated into MANY, an open source sys- tem combination software based on con- fusion networks developed at LIUM. The hypotheses from Chinese-English MT sys- tems were combined with a new version of the software. MANY has been updated in order to use word confidence score and to boost n-grams occurring in input hypothe- ses. In this paper we propose either to use an adapted language model or adding some additional features in the decoder to boost certain n-grams probabilities. Ex- perimental results show that the updates yielded significant improvements in terms of BLEU score.","tags":null,"title":"Using Hypothesis Selection Based Features for Confusion Network MT System Combination","type":"publication"},{"authors":["**Sahar Ghannay**","Yannick Estève","Nathalie Camelin","Paule Deléglise"],"categories":null,"content":"","date":1473292800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1473292800,"objectID":"9ee53e30c6e3f42adb45d9d4f2d0a596","permalink":"https://saharghannay.github.io/publication/conference-paper/ghannay-2016-acoustic/","publishdate":"2016-09-08T00:00:00Z","relpermalink":"/publication/conference-paper/ghannay-2016-acoustic/","section":"publication","summary":"This paper focuses on error detection in Automatic Speech Recognition (ASR) outputs. A neural network architecture is proposed, which is well suited to handle continuous word rep- resentations, like word embeddings. In a previous study, the authors explored the use of linguistic word embeddings, and more particularly their combination. In this new study, the use of acoustic word embeddings is explored. Acoustic word em- beddings offer the opportunity of an a priori acoustic represen- tation of words that can be compared, in terms of similarity, to an embedded representation of the audio signal. First, we propose an approach to evaluate the intrinsic per- formances of acoustic word embeddings in comparison to orthographic representations in order to capture discriminative phonetic information. Since French language is targeted in experiments, a particular focus is made on homophone words. Then, the use of acoustic word embeddings is evaluated for ASR error detection. The proposed approach gets a classification error rate of 7.94% while the previous state-of-the-art CRF-based approach gets a CER of 8.56% on the outputs of the ASR system which won the ETAPE evaluation campaign on speech recognition of French broadcast news.","tags":null,"title":"Acoustic word embeddings for ASR error detection","type":"publication"},{"authors":["Yannick Estève","**Sahar Ghannay**","Nathalie Camelin"],"categories":null,"content":"","date":1472515200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1472515200,"objectID":"eaa734af2b528555fc88f061c9bf1a8c","permalink":"https://saharghannay.github.io/publication/conference-paper/esteve-2016-imp/","publishdate":"2016-08-30T00:00:00Z","relpermalink":"/publication/conference-paper/esteve-2016-imp/","section":"publication","summary":"Automatic speech recognition(ASR) offers the ability to access the semantic content present in spoken language within audio and video documents. While acoustic models based on deep neural networks have recently significantly improved the performances of ASR sys- tems, automatic transcriptions still contain errors. Errors perturb the exploitation of these ASR outputs by introducing noise to the text. To reduce this noise, it is possible to apply an ASR error detection in order to remove recognized words labelled as errors. This paper presents an approach that reaches very good results, better than previous state-of-the-art approaches. This work is based on a neural approach, and more especially on a study targeted to acoustic and linguistic word embeddings, that are representations of words in a continuous space. In comparison to the previous state-of-the-art approach which were based on Conditional Random Fields, our approach reduces the classification error rate by 7.2%.","tags":null,"title":"Recent improvements on error detection for automatic speech recognition","type":"publication"},{"authors":["**Sahar Ghannay**","Yannick Estève","Nathalie Camelin","Paule Deléglise"],"categories":null,"content":"","date":1471305600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1471305600,"objectID":"cd4fff3e423cd801a0aee78d2f48ac33","permalink":"https://saharghannay.github.io/publication/conference-paper/ghannay-2016-acouseval/","publishdate":"2016-08-16T00:00:00Z","relpermalink":"/publication/conference-paper/ghannay-2016-acouseval/","section":"publication","summary":"Recently, researchers in speech recogni- tion have started to reconsider using whole words as the basic modeling unit, instead of phonetic units. These systems rely on a function that embeds an arbitrary or fixed dimensional speech segments to a vec- tor in a fixed-dimensional space, named acoustic word embedding. Thus, speech segments of words that sound similarly will be projected in a close area in a con- tinuous space. This paper focuses on the evaluation of acoustic word embed- dings. We propose two approaches to eval- uate the intrinsic performances of acoustic word embeddings in comparison to ortho- graphic representations in order to eval- uate whether they capture discriminative phonetic information. Since French lan- guage is targeted in experiments, a partic- ular focus is made on homophone words.","tags":null,"title":"Evaluation of acoustic word embeddings","type":"publication"},{"authors":["**Sahar Ghannay**","Yannick Estève","Nathalie Camelin","Camille Dutrey","Fabian Santiago","Martine Adda-Decker"],"categories":null,"content":"","date":1467590400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1467590400,"objectID":"398e9f2790caaa08f168e0cb85673aa7","permalink":"https://saharghannay.github.io/publication/conference-paper/ghannay-2016-errprossf/","publishdate":"2016-07-04T00:00:00Z","relpermalink":"/publication/conference-paper/ghannay-2016-errprossf/","section":"publication","summary":"Recent advances in continuous word representation have been successfully used in several natural language processing tasks. This paper focuses on error prediction in Automatic Speech Recogni- tion (ASR) outputs and proposes to investigate the use of continuous word representation (word embeddings) within a neural network architecture. The main contribution of this paper is about word embeddings combination : several combination approaches are proposed in order to take advantage of their complementarity. The use of prosodic features, in addition to classical syntactic ones, is evaluated. Experiments are made on automatic transcriptions generated by the LIUM ASR system applied on the ETAPE corpus. They show that the proposed neural architecture, using an effective continuous word representation combination and prosodic features as additional features, outperforms significantly state-of-the-art approach based on the use of Conditional Random Fields. Last, the proposed system produces a well calibrated confidence measure, evaluated in terms of NCE.","tags":null,"title":"Utilisation des représentations continues des mots et des paramètres prosodiques pour la détection d'erreurs dans les transcriptions automatiques de la parole","type":"publication"},{"authors":["**Sahar Ghannay**","Benoit Favre","Yannick Estève","Nathalie Camelin"],"categories":null,"content":"","date":1463961600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1463961600,"objectID":"e8d3d7e9493b4612ae163faf73e4e095","permalink":"https://saharghannay.github.io/publication/conference-paper/ghannay-2016-weevaluation/","publishdate":"2016-05-23T00:00:00Z","relpermalink":"/publication/conference-paper/ghannay-2016-weevaluation/","section":"publication","summary":"Word embeddings have been successfully used in several natural language processing tasks (NLP) and speech processing. Different approaches have been introduced to calculate word embeddings through neural networks. In the literature, many studies focused on word embedding evaluation, but for our knowledge, there are still some gaps. This paper presents a study focusing on a rigorous comparison of the performances of different kinds of word embeddings. These performances are evaluated on different NLP and linguistic tasks, while all the word embeddings are estimated on the same training data using the same vocabulary, the same number of dimensions, and other similar characteristics. The evaluation results reported in this paper match those in the literature, since they point out that the improvements achieved by a word embedding in one task are not consistently observed across all tasks. For that reason, this paper investigates and evaluates approaches to combine word embeddings in order to take advantage of their complementarity, and to look for the effective word embeddings that can achieve good performances on all tasks. As a conclusion, this paper provides new perceptions of intrinsic qualities of the famous word embedding families, which can be different from the ones provided by works previously published in the scientific literature.","tags":null,"title":"Word embedding evaluation and combination","type":"publication"},{"authors":null,"categories":null,"content":"","date":1461715200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1461715200,"objectID":"d1311ddf745551c9e117aa4bb7e28516","permalink":"https://saharghannay.github.io/project/external-project/","publishdate":"2016-04-27T00:00:00Z","relpermalink":"/project/external-project/","section":"project","summary":"An example of linking directly to an external project website using `external_link`.","tags":["Demo"],"title":"External Project","type":"project"},{"authors":null,"categories":null,"content":"Lorem ipsum dolor sit amet, consectetur adipiscing elit. Duis posuere tellus ac convallis placerat. Proin tincidunt magna sed ex sollicitudin condimentum. Sed ac faucibus dolor, scelerisque sollicitudin nisi. Cras purus urna, suscipit quis sapien eu, pulvinar tempor diam. Quisque risus orci, mollis id ante sit amet, gravida egestas nisl. Sed ac tempus magna. Proin in dui enim. Donec condimentum, sem id dapibus fringilla, tellus enim condimentum arcu, nec volutpat est felis vel metus. Vestibulum sit amet erat at nulla eleifend gravida.\nNullam vel molestie justo. Curabitur vitae efficitur leo. In hac habitasse platea dictumst. Sed pulvinar mauris dui, eget varius purus congue ac. Nulla euismod, lorem vel elementum dapibus, nunc justo porta mi, sed tempus est est vel tellus. Nam et enim eleifend, laoreet sem sit amet, elementum sem. Morbi ut leo congue, maximus velit ut, finibus arcu. In et libero cursus, rutrum risus non, molestie leo. Nullam congue quam et volutpat malesuada. Sed risus tortor, pulvinar et dictum nec, sodales non mi. Phasellus lacinia commodo laoreet. Nam mollis, erat in feugiat consectetur, purus eros egestas tellus, in auctor urna odio at nibh. Mauris imperdiet nisi ac magna convallis, at rhoncus ligula cursus.\nCras aliquam rhoncus ipsum, in hendrerit nunc mattis vitae. Duis vitae efficitur metus, ac tempus leo. Cras nec fringilla lacus. Quisque sit amet risus at ipsum pharetra commodo. Sed aliquam mauris at consequat eleifend. Praesent porta, augue sed viverra bibendum, neque ante euismod ante, in vehicula justo lorem ac eros. Suspendisse augue libero, venenatis eget tincidunt ut, malesuada at lorem. Donec vitae bibendum arcu. Aenean maximus nulla non pretium iaculis. Quisque imperdiet, nulla in pulvinar aliquet, velit quam ultrices quam, sit amet fringilla leo sem vel nunc. Mauris in lacinia lacus.\nSuspendisse a tincidunt lacus. Curabitur at urna sagittis, dictum ante sit amet, euismod magna. Sed rutrum massa id tortor commodo, vitae elementum turpis tempus. Lorem ipsum dolor sit amet, consectetur adipiscing elit. Aenean purus turpis, venenatis a ullamcorper nec, tincidunt et massa. Integer posuere quam rutrum arcu vehicula imperdiet. Mauris ullamcorper quam vitae purus congue, quis euismod magna eleifend. Vestibulum semper vel augue eget tincidunt. Fusce eget justo sodales, dapibus odio eu, ultrices lorem. Duis condimentum lorem id eros commodo, in facilisis mauris scelerisque. Morbi sed auctor leo. Nullam volutpat a lacus quis pharetra. Nulla congue rutrum magna a ornare.\nAliquam in turpis accumsan, malesuada nibh ut, hendrerit justo. Cum sociis natoque penatibus et magnis dis parturient montes, nascetur ridiculus mus. Quisque sed erat nec justo posuere suscipit. Donec ut efficitur arcu, in malesuada neque. Nunc dignissim nisl massa, id vulputate nunc pretium nec. Quisque eget urna in risus suscipit ultricies. Pellentesque odio odio, tincidunt in eleifend sed, posuere a diam. Nam gravida nisl convallis semper elementum. Morbi vitae felis faucibus, vulputate orci placerat, aliquet nisi. Aliquam erat volutpat. Maecenas sagittis pulvinar purus, sed porta quam laoreet at.\n","date":1461715200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1461715200,"objectID":"8f66d660a9a2edc2d08e68cc30f701f7","permalink":"https://saharghannay.github.io/project/internal-project/","publishdate":"2016-04-27T00:00:00Z","relpermalink":"/project/internal-project/","section":"project","summary":"An example of using the in-built project page.","tags":["Deep Learning"],"title":"Internal Project","type":"project"},{"authors":["**Sahar Ghannay**","Yannick Estève","Nathalie Camelin","Camille Dutrey","Fabian Santiago","Martine Adda-Decker"],"categories":null,"content":"","date":1448323200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1448323200,"objectID":"eb168a3745cae9c371b0f34b0ffd0c37","permalink":"https://saharghannay.github.io/publication/conference-paper/ghannay-2015-errpross/","publishdate":"2015-11-24T00:00:00Z","relpermalink":"/publication/conference-paper/ghannay-2015-errpross/","section":"publication","summary":"Recent advances in continuous word representation have been successfully used in several natural language processing tasks. This pa- per focuses on error prediction in Automatic Speech Recognition (ASR) outputs and proposes to investigate the use of continuous word repre- sentation (word embeddings) within a neural network architecture. The main contribution of this paper is about word embeddings combi- nation: several combination approaches are proposed in order to take advantage of their complementarity. The use of prosodic features, in addition to classical syntactic ones, is evaluated. Experiments are made on automatic transcriptions generated by the LIUM ASR system applied on the ETAPE corpus. They show that the proposed neural architecture, using an effective continuous word rep- resentation combination and prosodic features as additional features, outperforms significantly state-of-the-art approach based on the use of Conditional Random Fields. Last, the proposed system produces a well calibrated confidence measure, evaluated in terms of Normalized Cross Entropy.","tags":null,"title":"Combining continous word representation and prosodic features for ASR error prediction","type":"publication"},{"authors":["**Sahar Ghannay**","Nathalie Camelin","Yannick Estève"],"categories":null,"content":"","date":1441929600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1441929600,"objectID":"f2d4c317d584f362fc1784273163fd24","permalink":"https://saharghannay.github.io/publication/conference-paper/ghannay-2015-erranalyse/","publishdate":"2015-09-11T00:00:00Z","relpermalink":"/publication/conference-paper/ghannay-2015-erranalyse/","section":"publication","summary":"In this paper, we focus on error detection in Automatic Speech Recognition (ASR) outputs. We present a new ap- proach using continuous word representation (word embed- dings) through a neural network classifier. This classifier is in charge to attribute a label (error or correct ) for each word within an ASR hypothesis. Combining with word embeddings, inputs are based on a set of features (ASR confidence scores, lexical, and syntactic features, including contextual information from each word). Experiments were conducted on the automatic transcrip- tions generated by the LIUM ASR system applied on the ETAPE corpus (French broadcast news). They show that the proposed neural architecture outperforms the state-of-the- art approach based on the use of Conditional Random Fields (CRF). Particularly in this study, we are interested in the analysis of the classifier outputs, in order to perceive the errors that are hard to detect. Results of this analysis are presented in this paper, providing useful information in order to improve the proposed ASR error detection system.","tags":null,"title":"Which ASR errors are hard to detect?","type":"publication"},{"authors":["**Sahar Ghannay**","Yannick Estève","Nathalie Camelin"],"categories":null,"content":"","date":1440979200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1440979200,"objectID":"d44609281f9f605fbd902cc32f23ff39","permalink":"https://saharghannay.github.io/publication/conference-paper/ghannay-2015-wecomberr/","publishdate":"2015-08-31T00:00:00Z","relpermalink":"/publication/conference-paper/ghannay-2015-wecomberr/","section":"publication","summary":"This study focuses on error detection in Automatic Speech Recognition (ASR) output. We propose to build a confidence classifier based on a neural network architecture, which is in charge to attribute a label (error or correct) for each word within an ASR hypothesis. This classifier uses word embed- dings as inputs, in addition to ASR confidence-based, lexical and syntactic features. We propose to evaluate the impact of three different kinds of word embeddings on this error de- tection approach, and we present a solution to combine these three different types of word embeddings in order to take ad- vantage of their complementarity. In our experiments, different approaches are evaluated on the automatic transcriptions generated by two different ASR systems applied on the ETAPE corpus (French broadcast news). Experimental results show that the proposed neural architectures achieve a CER reduction comprised between 4% and 5.8% in error detection, depending on test dataset, in comparison with a state-of-the-art CRF approach.","tags":null,"title":"Word embeddings combination and neural networks for robustness in ASR error detection","type":"publication"},{"authors":null,"categories":null,"content":" 2010-2015 (55 hours) BSc level (L2) Data structures (linked list, hashtable, tree), pointers, recursivity ","date":-62135596800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":-62135596800,"objectID":"4fba0db4627d059e37fe8245553637cc","permalink":"https://saharghannay.github.io/project/cour-tranduction/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/project/cour-tranduction/","section":"project","summary":"BSc level (L2) course","tags":null,"title":"Algorithmic and programming","type":"project"}]